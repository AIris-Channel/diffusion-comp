{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uvit attention mode is xformers\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils\n",
    "from absl import logging\n",
    "import os\n",
    "import wandb\n",
    "import libs.autoencoder\n",
    "import clip\n",
    "from libs.clip import FrozenCLIPEmbedder\n",
    "from libs.caption_decoder import CaptionDecoder\n",
    "from torch.utils.data import DataLoader\n",
    "from libs.schedule import stable_diffusion_beta_schedule, Schedule, LSimple_T2I\n",
    "import argparse\n",
    "import yaml\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from libs.data import PersonalizedBase\n",
    "from libs.uvit_multi_post_ln_v1 import UViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # key args\n",
    "    parser.add_argument('-d', '--data', type=str,\n",
    "                        default=\"train_data/boy1\", help=\"datadir\")\n",
    "    parser.add_argument('-o', \"--outdir\", type=str,\n",
    "                        default=\"model_ouput/boy1\", help=\"output of model\")\n",
    "\n",
    "    # args of logging\n",
    "    parser.add_argument(\"--logdir\", type=str, default=\"logs\",\n",
    "                        help=\"the dir to put logs\")\n",
    "    parser.add_argument(\"--nnet_path\", type=str,\n",
    "                        default=\"models/uvit_v1.pth\", help=\"nnet path to resume\")\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.unidiffuserv1 import get_config\n",
    "config = get_config()\n",
    "config.nnet_path = \"models/uvit_v1.pth\"\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_state = utils.initialize_train_state(config, device, uvit_class=UViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UViT(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(4, 1536, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (time_img_embed): Identity()\n",
       "  (time_text_embed): Identity()\n",
       "  (text_embed): Linear(in_features=64, out_features=1536, bias=True)\n",
       "  (text_out): Linear(in_features=1536, out_features=64, bias=True)\n",
       "  (clip_img_embed): Linear(in_features=512, out_features=1536, bias=True)\n",
       "  (clip_img_out): Linear(in_features=1536, out_features=512, bias=True)\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (in_blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): Block(\n",
       "    (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (out_blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  (decoder_pred): Linear(in_features=1536, out_features=16, bias=True)\n",
       "  (token_embedding): Embedding(2, 1536)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_state.nnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " patch_embed\n",
      " patch_embed.proj\n",
      " time_img_embed\n",
      " time_text_embed\n",
      " text_embed\n",
      " text_out\n",
      " clip_img_embed\n",
      " clip_img_out\n",
      " pos_drop\n",
      " in_blocks\n",
      " in_blocks.0\n",
      " in_blocks.0.norm2\n",
      " in_blocks.0.attn\n",
      " in_blocks.0.attn.qkv\n",
      " in_blocks.0.attn.attn_drop\n",
      " in_blocks.0.attn.proj\n",
      " in_blocks.0.attn.proj_drop\n",
      " in_blocks.0.drop_path\n",
      " in_blocks.0.norm3\n",
      " in_blocks.0.mlp\n",
      " in_blocks.0.mlp.fc1\n",
      " in_blocks.0.mlp.act\n",
      " in_blocks.0.mlp.fc2\n",
      " in_blocks.0.mlp.drop\n",
      " in_blocks.1\n",
      " in_blocks.1.norm2\n",
      " in_blocks.1.attn\n",
      " in_blocks.1.attn.qkv\n",
      " in_blocks.1.attn.attn_drop\n",
      " in_blocks.1.attn.proj\n",
      " in_blocks.1.attn.proj_drop\n",
      " in_blocks.1.drop_path\n",
      " in_blocks.1.norm3\n",
      " in_blocks.1.mlp\n",
      " in_blocks.1.mlp.fc1\n",
      " in_blocks.1.mlp.act\n",
      " in_blocks.1.mlp.fc2\n",
      " in_blocks.1.mlp.drop\n",
      " in_blocks.2\n",
      " in_blocks.2.norm2\n",
      " in_blocks.2.attn\n",
      " in_blocks.2.attn.qkv\n",
      " in_blocks.2.attn.attn_drop\n",
      " in_blocks.2.attn.proj\n",
      " in_blocks.2.attn.proj_drop\n",
      " in_blocks.2.drop_path\n",
      " in_blocks.2.norm3\n",
      " in_blocks.2.mlp\n",
      " in_blocks.2.mlp.fc1\n",
      " in_blocks.2.mlp.act\n",
      " in_blocks.2.mlp.fc2\n",
      " in_blocks.2.mlp.drop\n",
      " in_blocks.3\n",
      " in_blocks.3.norm2\n",
      " in_blocks.3.attn\n",
      " in_blocks.3.attn.qkv\n",
      " in_blocks.3.attn.attn_drop\n",
      " in_blocks.3.attn.proj\n",
      " in_blocks.3.attn.proj_drop\n",
      " in_blocks.3.drop_path\n",
      " in_blocks.3.norm3\n",
      " in_blocks.3.mlp\n",
      " in_blocks.3.mlp.fc1\n",
      " in_blocks.3.mlp.act\n",
      " in_blocks.3.mlp.fc2\n",
      " in_blocks.3.mlp.drop\n",
      " in_blocks.4\n",
      " in_blocks.4.norm2\n",
      " in_blocks.4.attn\n",
      " in_blocks.4.attn.qkv\n",
      " in_blocks.4.attn.attn_drop\n",
      " in_blocks.4.attn.proj\n",
      " in_blocks.4.attn.proj_drop\n",
      " in_blocks.4.drop_path\n",
      " in_blocks.4.norm3\n",
      " in_blocks.4.mlp\n",
      " in_blocks.4.mlp.fc1\n",
      " in_blocks.4.mlp.act\n",
      " in_blocks.4.mlp.fc2\n",
      " in_blocks.4.mlp.drop\n",
      " in_blocks.5\n",
      " in_blocks.5.norm2\n",
      " in_blocks.5.attn\n",
      " in_blocks.5.attn.qkv\n",
      " in_blocks.5.attn.attn_drop\n",
      " in_blocks.5.attn.proj\n",
      " in_blocks.5.attn.proj_drop\n",
      " in_blocks.5.drop_path\n",
      " in_blocks.5.norm3\n",
      " in_blocks.5.mlp\n",
      " in_blocks.5.mlp.fc1\n",
      " in_blocks.5.mlp.act\n",
      " in_blocks.5.mlp.fc2\n",
      " in_blocks.5.mlp.drop\n",
      " in_blocks.6\n",
      " in_blocks.6.norm2\n",
      " in_blocks.6.attn\n",
      " in_blocks.6.attn.qkv\n",
      " in_blocks.6.attn.attn_drop\n",
      " in_blocks.6.attn.proj\n",
      " in_blocks.6.attn.proj_drop\n",
      " in_blocks.6.drop_path\n",
      " in_blocks.6.norm3\n",
      " in_blocks.6.mlp\n",
      " in_blocks.6.mlp.fc1\n",
      " in_blocks.6.mlp.act\n",
      " in_blocks.6.mlp.fc2\n",
      " in_blocks.6.mlp.drop\n",
      " in_blocks.7\n",
      " in_blocks.7.norm2\n",
      " in_blocks.7.attn\n",
      " in_blocks.7.attn.qkv\n",
      " in_blocks.7.attn.attn_drop\n",
      " in_blocks.7.attn.proj\n",
      " in_blocks.7.attn.proj_drop\n",
      " in_blocks.7.drop_path\n",
      " in_blocks.7.norm3\n",
      " in_blocks.7.mlp\n",
      " in_blocks.7.mlp.fc1\n",
      " in_blocks.7.mlp.act\n",
      " in_blocks.7.mlp.fc2\n",
      " in_blocks.7.mlp.drop\n",
      " in_blocks.8\n",
      " in_blocks.8.norm2\n",
      " in_blocks.8.attn\n",
      " in_blocks.8.attn.qkv\n",
      " in_blocks.8.attn.attn_drop\n",
      " in_blocks.8.attn.proj\n",
      " in_blocks.8.attn.proj_drop\n",
      " in_blocks.8.drop_path\n",
      " in_blocks.8.norm3\n",
      " in_blocks.8.mlp\n",
      " in_blocks.8.mlp.fc1\n",
      " in_blocks.8.mlp.act\n",
      " in_blocks.8.mlp.fc2\n",
      " in_blocks.8.mlp.drop\n",
      " in_blocks.9\n",
      " in_blocks.9.norm2\n",
      " in_blocks.9.attn\n",
      " in_blocks.9.attn.qkv\n",
      " in_blocks.9.attn.attn_drop\n",
      " in_blocks.9.attn.proj\n",
      " in_blocks.9.attn.proj_drop\n",
      " in_blocks.9.drop_path\n",
      " in_blocks.9.norm3\n",
      " in_blocks.9.mlp\n",
      " in_blocks.9.mlp.fc1\n",
      " in_blocks.9.mlp.act\n",
      " in_blocks.9.mlp.fc2\n",
      " in_blocks.9.mlp.drop\n",
      " in_blocks.10\n",
      " in_blocks.10.norm2\n",
      " in_blocks.10.attn\n",
      " in_blocks.10.attn.qkv\n",
      " in_blocks.10.attn.attn_drop\n",
      " in_blocks.10.attn.proj\n",
      " in_blocks.10.attn.proj_drop\n",
      " in_blocks.10.drop_path\n",
      " in_blocks.10.norm3\n",
      " in_blocks.10.mlp\n",
      " in_blocks.10.mlp.fc1\n",
      " in_blocks.10.mlp.act\n",
      " in_blocks.10.mlp.fc2\n",
      " in_blocks.10.mlp.drop\n",
      " in_blocks.11\n",
      " in_blocks.11.norm2\n",
      " in_blocks.11.attn\n",
      " in_blocks.11.attn.qkv\n",
      " in_blocks.11.attn.attn_drop\n",
      " in_blocks.11.attn.proj\n",
      " in_blocks.11.attn.proj_drop\n",
      " in_blocks.11.drop_path\n",
      " in_blocks.11.norm3\n",
      " in_blocks.11.mlp\n",
      " in_blocks.11.mlp.fc1\n",
      " in_blocks.11.mlp.act\n",
      " in_blocks.11.mlp.fc2\n",
      " in_blocks.11.mlp.drop\n",
      " in_blocks.12\n",
      " in_blocks.12.norm2\n",
      " in_blocks.12.attn\n",
      " in_blocks.12.attn.qkv\n",
      " in_blocks.12.attn.attn_drop\n",
      " in_blocks.12.attn.proj\n",
      " in_blocks.12.attn.proj_drop\n",
      " in_blocks.12.drop_path\n",
      " in_blocks.12.norm3\n",
      " in_blocks.12.mlp\n",
      " in_blocks.12.mlp.fc1\n",
      " in_blocks.12.mlp.act\n",
      " in_blocks.12.mlp.fc2\n",
      " in_blocks.12.mlp.drop\n",
      " in_blocks.13\n",
      " in_blocks.13.norm2\n",
      " in_blocks.13.attn\n",
      " in_blocks.13.attn.qkv\n",
      " in_blocks.13.attn.attn_drop\n",
      " in_blocks.13.attn.proj\n",
      " in_blocks.13.attn.proj_drop\n",
      " in_blocks.13.drop_path\n",
      " in_blocks.13.norm3\n",
      " in_blocks.13.mlp\n",
      " in_blocks.13.mlp.fc1\n",
      " in_blocks.13.mlp.act\n",
      " in_blocks.13.mlp.fc2\n",
      " in_blocks.13.mlp.drop\n",
      " in_blocks.14\n",
      " in_blocks.14.norm2\n",
      " in_blocks.14.attn\n",
      " in_blocks.14.attn.qkv\n",
      " in_blocks.14.attn.attn_drop\n",
      " in_blocks.14.attn.proj\n",
      " in_blocks.14.attn.proj_drop\n",
      " in_blocks.14.drop_path\n",
      " in_blocks.14.norm3\n",
      " in_blocks.14.mlp\n",
      " in_blocks.14.mlp.fc1\n",
      " in_blocks.14.mlp.act\n",
      " in_blocks.14.mlp.fc2\n",
      " in_blocks.14.mlp.drop\n",
      " mid_block\n",
      " mid_block.norm2\n",
      " mid_block.attn\n",
      " mid_block.attn.qkv\n",
      " mid_block.attn.attn_drop\n",
      " mid_block.attn.proj\n",
      " mid_block.attn.proj_drop\n",
      " mid_block.drop_path\n",
      " mid_block.norm3\n",
      " mid_block.mlp\n",
      " mid_block.mlp.fc1\n",
      " mid_block.mlp.act\n",
      " mid_block.mlp.fc2\n",
      " mid_block.mlp.drop\n",
      " out_blocks\n",
      " out_blocks.0\n",
      " out_blocks.0.norm1\n",
      " out_blocks.0.norm2\n",
      " out_blocks.0.attn\n",
      " out_blocks.0.attn.qkv\n",
      " out_blocks.0.attn.attn_drop\n",
      " out_blocks.0.attn.proj\n",
      " out_blocks.0.attn.proj_drop\n",
      " out_blocks.0.drop_path\n",
      " out_blocks.0.norm3\n",
      " out_blocks.0.mlp\n",
      " out_blocks.0.mlp.fc1\n",
      " out_blocks.0.mlp.act\n",
      " out_blocks.0.mlp.fc2\n",
      " out_blocks.0.mlp.drop\n",
      " out_blocks.0.skip_linear\n",
      " out_blocks.1\n",
      " out_blocks.1.norm1\n",
      " out_blocks.1.norm2\n",
      " out_blocks.1.attn\n",
      " out_blocks.1.attn.qkv\n",
      " out_blocks.1.attn.attn_drop\n",
      " out_blocks.1.attn.proj\n",
      " out_blocks.1.attn.proj_drop\n",
      " out_blocks.1.drop_path\n",
      " out_blocks.1.norm3\n",
      " out_blocks.1.mlp\n",
      " out_blocks.1.mlp.fc1\n",
      " out_blocks.1.mlp.act\n",
      " out_blocks.1.mlp.fc2\n",
      " out_blocks.1.mlp.drop\n",
      " out_blocks.1.skip_linear\n",
      " out_blocks.2\n",
      " out_blocks.2.norm1\n",
      " out_blocks.2.norm2\n",
      " out_blocks.2.attn\n",
      " out_blocks.2.attn.qkv\n",
      " out_blocks.2.attn.attn_drop\n",
      " out_blocks.2.attn.proj\n",
      " out_blocks.2.attn.proj_drop\n",
      " out_blocks.2.drop_path\n",
      " out_blocks.2.norm3\n",
      " out_blocks.2.mlp\n",
      " out_blocks.2.mlp.fc1\n",
      " out_blocks.2.mlp.act\n",
      " out_blocks.2.mlp.fc2\n",
      " out_blocks.2.mlp.drop\n",
      " out_blocks.2.skip_linear\n",
      " out_blocks.3\n",
      " out_blocks.3.norm1\n",
      " out_blocks.3.norm2\n",
      " out_blocks.3.attn\n",
      " out_blocks.3.attn.qkv\n",
      " out_blocks.3.attn.attn_drop\n",
      " out_blocks.3.attn.proj\n",
      " out_blocks.3.attn.proj_drop\n",
      " out_blocks.3.drop_path\n",
      " out_blocks.3.norm3\n",
      " out_blocks.3.mlp\n",
      " out_blocks.3.mlp.fc1\n",
      " out_blocks.3.mlp.act\n",
      " out_blocks.3.mlp.fc2\n",
      " out_blocks.3.mlp.drop\n",
      " out_blocks.3.skip_linear\n",
      " out_blocks.4\n",
      " out_blocks.4.norm1\n",
      " out_blocks.4.norm2\n",
      " out_blocks.4.attn\n",
      " out_blocks.4.attn.qkv\n",
      " out_blocks.4.attn.attn_drop\n",
      " out_blocks.4.attn.proj\n",
      " out_blocks.4.attn.proj_drop\n",
      " out_blocks.4.drop_path\n",
      " out_blocks.4.norm3\n",
      " out_blocks.4.mlp\n",
      " out_blocks.4.mlp.fc1\n",
      " out_blocks.4.mlp.act\n",
      " out_blocks.4.mlp.fc2\n",
      " out_blocks.4.mlp.drop\n",
      " out_blocks.4.skip_linear\n",
      " out_blocks.5\n",
      " out_blocks.5.norm1\n",
      " out_blocks.5.norm2\n",
      " out_blocks.5.attn\n",
      " out_blocks.5.attn.qkv\n",
      " out_blocks.5.attn.attn_drop\n",
      " out_blocks.5.attn.proj\n",
      " out_blocks.5.attn.proj_drop\n",
      " out_blocks.5.drop_path\n",
      " out_blocks.5.norm3\n",
      " out_blocks.5.mlp\n",
      " out_blocks.5.mlp.fc1\n",
      " out_blocks.5.mlp.act\n",
      " out_blocks.5.mlp.fc2\n",
      " out_blocks.5.mlp.drop\n",
      " out_blocks.5.skip_linear\n",
      " out_blocks.6\n",
      " out_blocks.6.norm1\n",
      " out_blocks.6.norm2\n",
      " out_blocks.6.attn\n",
      " out_blocks.6.attn.qkv\n",
      " out_blocks.6.attn.attn_drop\n",
      " out_blocks.6.attn.proj\n",
      " out_blocks.6.attn.proj_drop\n",
      " out_blocks.6.drop_path\n",
      " out_blocks.6.norm3\n",
      " out_blocks.6.mlp\n",
      " out_blocks.6.mlp.fc1\n",
      " out_blocks.6.mlp.act\n",
      " out_blocks.6.mlp.fc2\n",
      " out_blocks.6.mlp.drop\n",
      " out_blocks.6.skip_linear\n",
      " out_blocks.7\n",
      " out_blocks.7.norm1\n",
      " out_blocks.7.norm2\n",
      " out_blocks.7.attn\n",
      " out_blocks.7.attn.qkv\n",
      " out_blocks.7.attn.attn_drop\n",
      " out_blocks.7.attn.proj\n",
      " out_blocks.7.attn.proj_drop\n",
      " out_blocks.7.drop_path\n",
      " out_blocks.7.norm3\n",
      " out_blocks.7.mlp\n",
      " out_blocks.7.mlp.fc1\n",
      " out_blocks.7.mlp.act\n",
      " out_blocks.7.mlp.fc2\n",
      " out_blocks.7.mlp.drop\n",
      " out_blocks.7.skip_linear\n",
      " out_blocks.8\n",
      " out_blocks.8.norm1\n",
      " out_blocks.8.norm2\n",
      " out_blocks.8.attn\n",
      " out_blocks.8.attn.qkv\n",
      " out_blocks.8.attn.attn_drop\n",
      " out_blocks.8.attn.proj\n",
      " out_blocks.8.attn.proj_drop\n",
      " out_blocks.8.drop_path\n",
      " out_blocks.8.norm3\n",
      " out_blocks.8.mlp\n",
      " out_blocks.8.mlp.fc1\n",
      " out_blocks.8.mlp.act\n",
      " out_blocks.8.mlp.fc2\n",
      " out_blocks.8.mlp.drop\n",
      " out_blocks.8.skip_linear\n",
      " out_blocks.9\n",
      " out_blocks.9.norm1\n",
      " out_blocks.9.norm2\n",
      " out_blocks.9.attn\n",
      " out_blocks.9.attn.qkv\n",
      " out_blocks.9.attn.attn_drop\n",
      " out_blocks.9.attn.proj\n",
      " out_blocks.9.attn.proj_drop\n",
      " out_blocks.9.drop_path\n",
      " out_blocks.9.norm3\n",
      " out_blocks.9.mlp\n",
      " out_blocks.9.mlp.fc1\n",
      " out_blocks.9.mlp.act\n",
      " out_blocks.9.mlp.fc2\n",
      " out_blocks.9.mlp.drop\n",
      " out_blocks.9.skip_linear\n",
      " out_blocks.10\n",
      " out_blocks.10.norm1\n",
      " out_blocks.10.norm2\n",
      " out_blocks.10.attn\n",
      " out_blocks.10.attn.qkv\n",
      " out_blocks.10.attn.attn_drop\n",
      " out_blocks.10.attn.proj\n",
      " out_blocks.10.attn.proj_drop\n",
      " out_blocks.10.drop_path\n",
      " out_blocks.10.norm3\n",
      " out_blocks.10.mlp\n",
      " out_blocks.10.mlp.fc1\n",
      " out_blocks.10.mlp.act\n",
      " out_blocks.10.mlp.fc2\n",
      " out_blocks.10.mlp.drop\n",
      " out_blocks.10.skip_linear\n",
      " out_blocks.11\n",
      " out_blocks.11.norm1\n",
      " out_blocks.11.norm2\n",
      " out_blocks.11.attn\n",
      " out_blocks.11.attn.qkv\n",
      " out_blocks.11.attn.attn_drop\n",
      " out_blocks.11.attn.proj\n",
      " out_blocks.11.attn.proj_drop\n",
      " out_blocks.11.drop_path\n",
      " out_blocks.11.norm3\n",
      " out_blocks.11.mlp\n",
      " out_blocks.11.mlp.fc1\n",
      " out_blocks.11.mlp.act\n",
      " out_blocks.11.mlp.fc2\n",
      " out_blocks.11.mlp.drop\n",
      " out_blocks.11.skip_linear\n",
      " out_blocks.12\n",
      " out_blocks.12.norm1\n",
      " out_blocks.12.norm2\n",
      " out_blocks.12.attn\n",
      " out_blocks.12.attn.qkv\n",
      " out_blocks.12.attn.attn_drop\n",
      " out_blocks.12.attn.proj\n",
      " out_blocks.12.attn.proj_drop\n",
      " out_blocks.12.drop_path\n",
      " out_blocks.12.norm3\n",
      " out_blocks.12.mlp\n",
      " out_blocks.12.mlp.fc1\n",
      " out_blocks.12.mlp.act\n",
      " out_blocks.12.mlp.fc2\n",
      " out_blocks.12.mlp.drop\n",
      " out_blocks.12.skip_linear\n",
      " out_blocks.13\n",
      " out_blocks.13.norm1\n",
      " out_blocks.13.norm2\n",
      " out_blocks.13.attn\n",
      " out_blocks.13.attn.qkv\n",
      " out_blocks.13.attn.attn_drop\n",
      " out_blocks.13.attn.proj\n",
      " out_blocks.13.attn.proj_drop\n",
      " out_blocks.13.drop_path\n",
      " out_blocks.13.norm3\n",
      " out_blocks.13.mlp\n",
      " out_blocks.13.mlp.fc1\n",
      " out_blocks.13.mlp.act\n",
      " out_blocks.13.mlp.fc2\n",
      " out_blocks.13.mlp.drop\n",
      " out_blocks.13.skip_linear\n",
      " out_blocks.14\n",
      " out_blocks.14.norm1\n",
      " out_blocks.14.norm2\n",
      " out_blocks.14.attn\n",
      " out_blocks.14.attn.qkv\n",
      " out_blocks.14.attn.attn_drop\n",
      " out_blocks.14.attn.proj\n",
      " out_blocks.14.attn.proj_drop\n",
      " out_blocks.14.drop_path\n",
      " out_blocks.14.norm3\n",
      " out_blocks.14.mlp\n",
      " out_blocks.14.mlp.fc1\n",
      " out_blocks.14.mlp.act\n",
      " out_blocks.14.mlp.fc2\n",
      " out_blocks.14.mlp.drop\n",
      " out_blocks.14.skip_linear\n",
      " norm\n",
      " decoder_pred\n",
      " token_embedding\n",
      "patch_embed \n",
      "patch_embed proj\n",
      "patch_embed.proj \n",
      "time_img_embed \n",
      "time_text_embed \n",
      "text_embed \n",
      "text_out \n",
      "clip_img_embed \n",
      "clip_img_out \n",
      "pos_drop \n",
      "in_blocks \n",
      "in_blocks 0\n",
      "in_blocks 0.norm2\n",
      "in_blocks 0.attn\n",
      "in_blocks 0.attn.qkv\n",
      "in_blocks 0.attn.attn_drop\n",
      "in_blocks 0.attn.proj\n",
      "in_blocks 0.attn.proj_drop\n",
      "in_blocks 0.drop_path\n",
      "in_blocks 0.norm3\n",
      "in_blocks 0.mlp\n",
      "in_blocks 0.mlp.fc1\n",
      "in_blocks 0.mlp.act\n",
      "in_blocks 0.mlp.fc2\n",
      "in_blocks 0.mlp.drop\n",
      "in_blocks 1\n",
      "in_blocks 1.norm2\n",
      "in_blocks 1.attn\n",
      "in_blocks 1.attn.qkv\n",
      "in_blocks 1.attn.attn_drop\n",
      "in_blocks 1.attn.proj\n",
      "in_blocks 1.attn.proj_drop\n",
      "in_blocks 1.drop_path\n",
      "in_blocks 1.norm3\n",
      "in_blocks 1.mlp\n",
      "in_blocks 1.mlp.fc1\n",
      "in_blocks 1.mlp.act\n",
      "in_blocks 1.mlp.fc2\n",
      "in_blocks 1.mlp.drop\n",
      "in_blocks 2\n",
      "in_blocks 2.norm2\n",
      "in_blocks 2.attn\n",
      "in_blocks 2.attn.qkv\n",
      "in_blocks 2.attn.attn_drop\n",
      "in_blocks 2.attn.proj\n",
      "in_blocks 2.attn.proj_drop\n",
      "in_blocks 2.drop_path\n",
      "in_blocks 2.norm3\n",
      "in_blocks 2.mlp\n",
      "in_blocks 2.mlp.fc1\n",
      "in_blocks 2.mlp.act\n",
      "in_blocks 2.mlp.fc2\n",
      "in_blocks 2.mlp.drop\n",
      "in_blocks 3\n",
      "in_blocks 3.norm2\n",
      "in_blocks 3.attn\n",
      "in_blocks 3.attn.qkv\n",
      "in_blocks 3.attn.attn_drop\n",
      "in_blocks 3.attn.proj\n",
      "in_blocks 3.attn.proj_drop\n",
      "in_blocks 3.drop_path\n",
      "in_blocks 3.norm3\n",
      "in_blocks 3.mlp\n",
      "in_blocks 3.mlp.fc1\n",
      "in_blocks 3.mlp.act\n",
      "in_blocks 3.mlp.fc2\n",
      "in_blocks 3.mlp.drop\n",
      "in_blocks 4\n",
      "in_blocks 4.norm2\n",
      "in_blocks 4.attn\n",
      "in_blocks 4.attn.qkv\n",
      "in_blocks 4.attn.attn_drop\n",
      "in_blocks 4.attn.proj\n",
      "in_blocks 4.attn.proj_drop\n",
      "in_blocks 4.drop_path\n",
      "in_blocks 4.norm3\n",
      "in_blocks 4.mlp\n",
      "in_blocks 4.mlp.fc1\n",
      "in_blocks 4.mlp.act\n",
      "in_blocks 4.mlp.fc2\n",
      "in_blocks 4.mlp.drop\n",
      "in_blocks 5\n",
      "in_blocks 5.norm2\n",
      "in_blocks 5.attn\n",
      "in_blocks 5.attn.qkv\n",
      "in_blocks 5.attn.attn_drop\n",
      "in_blocks 5.attn.proj\n",
      "in_blocks 5.attn.proj_drop\n",
      "in_blocks 5.drop_path\n",
      "in_blocks 5.norm3\n",
      "in_blocks 5.mlp\n",
      "in_blocks 5.mlp.fc1\n",
      "in_blocks 5.mlp.act\n",
      "in_blocks 5.mlp.fc2\n",
      "in_blocks 5.mlp.drop\n",
      "in_blocks 6\n",
      "in_blocks 6.norm2\n",
      "in_blocks 6.attn\n",
      "in_blocks 6.attn.qkv\n",
      "in_blocks 6.attn.attn_drop\n",
      "in_blocks 6.attn.proj\n",
      "in_blocks 6.attn.proj_drop\n",
      "in_blocks 6.drop_path\n",
      "in_blocks 6.norm3\n",
      "in_blocks 6.mlp\n",
      "in_blocks 6.mlp.fc1\n",
      "in_blocks 6.mlp.act\n",
      "in_blocks 6.mlp.fc2\n",
      "in_blocks 6.mlp.drop\n",
      "in_blocks 7\n",
      "in_blocks 7.norm2\n",
      "in_blocks 7.attn\n",
      "in_blocks 7.attn.qkv\n",
      "in_blocks 7.attn.attn_drop\n",
      "in_blocks 7.attn.proj\n",
      "in_blocks 7.attn.proj_drop\n",
      "in_blocks 7.drop_path\n",
      "in_blocks 7.norm3\n",
      "in_blocks 7.mlp\n",
      "in_blocks 7.mlp.fc1\n",
      "in_blocks 7.mlp.act\n",
      "in_blocks 7.mlp.fc2\n",
      "in_blocks 7.mlp.drop\n",
      "in_blocks 8\n",
      "in_blocks 8.norm2\n",
      "in_blocks 8.attn\n",
      "in_blocks 8.attn.qkv\n",
      "in_blocks 8.attn.attn_drop\n",
      "in_blocks 8.attn.proj\n",
      "in_blocks 8.attn.proj_drop\n",
      "in_blocks 8.drop_path\n",
      "in_blocks 8.norm3\n",
      "in_blocks 8.mlp\n",
      "in_blocks 8.mlp.fc1\n",
      "in_blocks 8.mlp.act\n",
      "in_blocks 8.mlp.fc2\n",
      "in_blocks 8.mlp.drop\n",
      "in_blocks 9\n",
      "in_blocks 9.norm2\n",
      "in_blocks 9.attn\n",
      "in_blocks 9.attn.qkv\n",
      "in_blocks 9.attn.attn_drop\n",
      "in_blocks 9.attn.proj\n",
      "in_blocks 9.attn.proj_drop\n",
      "in_blocks 9.drop_path\n",
      "in_blocks 9.norm3\n",
      "in_blocks 9.mlp\n",
      "in_blocks 9.mlp.fc1\n",
      "in_blocks 9.mlp.act\n",
      "in_blocks 9.mlp.fc2\n",
      "in_blocks 9.mlp.drop\n",
      "in_blocks 10\n",
      "in_blocks 10.norm2\n",
      "in_blocks 10.attn\n",
      "in_blocks 10.attn.qkv\n",
      "in_blocks 10.attn.attn_drop\n",
      "in_blocks 10.attn.proj\n",
      "in_blocks 10.attn.proj_drop\n",
      "in_blocks 10.drop_path\n",
      "in_blocks 10.norm3\n",
      "in_blocks 10.mlp\n",
      "in_blocks 10.mlp.fc1\n",
      "in_blocks 10.mlp.act\n",
      "in_blocks 10.mlp.fc2\n",
      "in_blocks 10.mlp.drop\n",
      "in_blocks 11\n",
      "in_blocks 11.norm2\n",
      "in_blocks 11.attn\n",
      "in_blocks 11.attn.qkv\n",
      "in_blocks 11.attn.attn_drop\n",
      "in_blocks 11.attn.proj\n",
      "in_blocks 11.attn.proj_drop\n",
      "in_blocks 11.drop_path\n",
      "in_blocks 11.norm3\n",
      "in_blocks 11.mlp\n",
      "in_blocks 11.mlp.fc1\n",
      "in_blocks 11.mlp.act\n",
      "in_blocks 11.mlp.fc2\n",
      "in_blocks 11.mlp.drop\n",
      "in_blocks 12\n",
      "in_blocks 12.norm2\n",
      "in_blocks 12.attn\n",
      "in_blocks 12.attn.qkv\n",
      "in_blocks 12.attn.attn_drop\n",
      "in_blocks 12.attn.proj\n",
      "in_blocks 12.attn.proj_drop\n",
      "in_blocks 12.drop_path\n",
      "in_blocks 12.norm3\n",
      "in_blocks 12.mlp\n",
      "in_blocks 12.mlp.fc1\n",
      "in_blocks 12.mlp.act\n",
      "in_blocks 12.mlp.fc2\n",
      "in_blocks 12.mlp.drop\n",
      "in_blocks 13\n",
      "in_blocks 13.norm2\n",
      "in_blocks 13.attn\n",
      "in_blocks 13.attn.qkv\n",
      "in_blocks 13.attn.attn_drop\n",
      "in_blocks 13.attn.proj\n",
      "in_blocks 13.attn.proj_drop\n",
      "in_blocks 13.drop_path\n",
      "in_blocks 13.norm3\n",
      "in_blocks 13.mlp\n",
      "in_blocks 13.mlp.fc1\n",
      "in_blocks 13.mlp.act\n",
      "in_blocks 13.mlp.fc2\n",
      "in_blocks 13.mlp.drop\n",
      "in_blocks 14\n",
      "in_blocks 14.norm2\n",
      "in_blocks 14.attn\n",
      "in_blocks 14.attn.qkv\n",
      "in_blocks 14.attn.attn_drop\n",
      "in_blocks 14.attn.proj\n",
      "in_blocks 14.attn.proj_drop\n",
      "in_blocks 14.drop_path\n",
      "in_blocks 14.norm3\n",
      "in_blocks 14.mlp\n",
      "in_blocks 14.mlp.fc1\n",
      "in_blocks 14.mlp.act\n",
      "in_blocks 14.mlp.fc2\n",
      "in_blocks 14.mlp.drop\n",
      "in_blocks.0 \n",
      "in_blocks.0 norm2\n",
      "in_blocks.0 attn\n",
      "in_blocks.0 attn.qkv\n",
      "in_blocks.0 attn.attn_drop\n",
      "in_blocks.0 attn.proj\n",
      "in_blocks.0 attn.proj_drop\n",
      "in_blocks.0 drop_path\n",
      "in_blocks.0 norm3\n",
      "in_blocks.0 mlp\n",
      "in_blocks.0 mlp.fc1\n",
      "in_blocks.0 mlp.act\n",
      "in_blocks.0 mlp.fc2\n",
      "in_blocks.0 mlp.drop\n",
      "in_blocks.0.norm2 \n",
      "in_blocks.0.attn \n",
      "in_blocks.0.attn qkv\n",
      "in_blocks.0.attn attn_drop\n",
      "in_blocks.0.attn proj\n",
      "in_blocks.0.attn proj_drop\n",
      "in_blocks.0.attn.qkv \n",
      "in_blocks.0.attn.attn_drop \n",
      "in_blocks.0.attn.proj \n",
      "in_blocks.0.attn.proj_drop \n",
      "in_blocks.0.drop_path \n",
      "in_blocks.0.norm3 \n",
      "in_blocks.0.mlp \n",
      "in_blocks.0.mlp fc1\n",
      "in_blocks.0.mlp act\n",
      "in_blocks.0.mlp fc2\n",
      "in_blocks.0.mlp drop\n",
      "in_blocks.0.mlp.fc1 \n",
      "in_blocks.0.mlp.act \n",
      "in_blocks.0.mlp.fc2 \n",
      "in_blocks.0.mlp.drop \n",
      "in_blocks.1 \n",
      "in_blocks.1 norm2\n",
      "in_blocks.1 attn\n",
      "in_blocks.1 attn.qkv\n",
      "in_blocks.1 attn.attn_drop\n",
      "in_blocks.1 attn.proj\n",
      "in_blocks.1 attn.proj_drop\n",
      "in_blocks.1 drop_path\n",
      "in_blocks.1 norm3\n",
      "in_blocks.1 mlp\n",
      "in_blocks.1 mlp.fc1\n",
      "in_blocks.1 mlp.act\n",
      "in_blocks.1 mlp.fc2\n",
      "in_blocks.1 mlp.drop\n",
      "in_blocks.1.norm2 \n",
      "in_blocks.1.attn \n",
      "in_blocks.1.attn qkv\n",
      "in_blocks.1.attn attn_drop\n",
      "in_blocks.1.attn proj\n",
      "in_blocks.1.attn proj_drop\n",
      "in_blocks.1.attn.qkv \n",
      "in_blocks.1.attn.attn_drop \n",
      "in_blocks.1.attn.proj \n",
      "in_blocks.1.attn.proj_drop \n",
      "in_blocks.1.drop_path \n",
      "in_blocks.1.norm3 \n",
      "in_blocks.1.mlp \n",
      "in_blocks.1.mlp fc1\n",
      "in_blocks.1.mlp act\n",
      "in_blocks.1.mlp fc2\n",
      "in_blocks.1.mlp drop\n",
      "in_blocks.1.mlp.fc1 \n",
      "in_blocks.1.mlp.act \n",
      "in_blocks.1.mlp.fc2 \n",
      "in_blocks.1.mlp.drop \n",
      "in_blocks.2 \n",
      "in_blocks.2 norm2\n",
      "in_blocks.2 attn\n",
      "in_blocks.2 attn.qkv\n",
      "in_blocks.2 attn.attn_drop\n",
      "in_blocks.2 attn.proj\n",
      "in_blocks.2 attn.proj_drop\n",
      "in_blocks.2 drop_path\n",
      "in_blocks.2 norm3\n",
      "in_blocks.2 mlp\n",
      "in_blocks.2 mlp.fc1\n",
      "in_blocks.2 mlp.act\n",
      "in_blocks.2 mlp.fc2\n",
      "in_blocks.2 mlp.drop\n",
      "in_blocks.2.norm2 \n",
      "in_blocks.2.attn \n",
      "in_blocks.2.attn qkv\n",
      "in_blocks.2.attn attn_drop\n",
      "in_blocks.2.attn proj\n",
      "in_blocks.2.attn proj_drop\n",
      "in_blocks.2.attn.qkv \n",
      "in_blocks.2.attn.attn_drop \n",
      "in_blocks.2.attn.proj \n",
      "in_blocks.2.attn.proj_drop \n",
      "in_blocks.2.drop_path \n",
      "in_blocks.2.norm3 \n",
      "in_blocks.2.mlp \n",
      "in_blocks.2.mlp fc1\n",
      "in_blocks.2.mlp act\n",
      "in_blocks.2.mlp fc2\n",
      "in_blocks.2.mlp drop\n",
      "in_blocks.2.mlp.fc1 \n",
      "in_blocks.2.mlp.act \n",
      "in_blocks.2.mlp.fc2 \n",
      "in_blocks.2.mlp.drop \n",
      "in_blocks.3 \n",
      "in_blocks.3 norm2\n",
      "in_blocks.3 attn\n",
      "in_blocks.3 attn.qkv\n",
      "in_blocks.3 attn.attn_drop\n",
      "in_blocks.3 attn.proj\n",
      "in_blocks.3 attn.proj_drop\n",
      "in_blocks.3 drop_path\n",
      "in_blocks.3 norm3\n",
      "in_blocks.3 mlp\n",
      "in_blocks.3 mlp.fc1\n",
      "in_blocks.3 mlp.act\n",
      "in_blocks.3 mlp.fc2\n",
      "in_blocks.3 mlp.drop\n",
      "in_blocks.3.norm2 \n",
      "in_blocks.3.attn \n",
      "in_blocks.3.attn qkv\n",
      "in_blocks.3.attn attn_drop\n",
      "in_blocks.3.attn proj\n",
      "in_blocks.3.attn proj_drop\n",
      "in_blocks.3.attn.qkv \n",
      "in_blocks.3.attn.attn_drop \n",
      "in_blocks.3.attn.proj \n",
      "in_blocks.3.attn.proj_drop \n",
      "in_blocks.3.drop_path \n",
      "in_blocks.3.norm3 \n",
      "in_blocks.3.mlp \n",
      "in_blocks.3.mlp fc1\n",
      "in_blocks.3.mlp act\n",
      "in_blocks.3.mlp fc2\n",
      "in_blocks.3.mlp drop\n",
      "in_blocks.3.mlp.fc1 \n",
      "in_blocks.3.mlp.act \n",
      "in_blocks.3.mlp.fc2 \n",
      "in_blocks.3.mlp.drop \n",
      "in_blocks.4 \n",
      "in_blocks.4 norm2\n",
      "in_blocks.4 attn\n",
      "in_blocks.4 attn.qkv\n",
      "in_blocks.4 attn.attn_drop\n",
      "in_blocks.4 attn.proj\n",
      "in_blocks.4 attn.proj_drop\n",
      "in_blocks.4 drop_path\n",
      "in_blocks.4 norm3\n",
      "in_blocks.4 mlp\n",
      "in_blocks.4 mlp.fc1\n",
      "in_blocks.4 mlp.act\n",
      "in_blocks.4 mlp.fc2\n",
      "in_blocks.4 mlp.drop\n",
      "in_blocks.4.norm2 \n",
      "in_blocks.4.attn \n",
      "in_blocks.4.attn qkv\n",
      "in_blocks.4.attn attn_drop\n",
      "in_blocks.4.attn proj\n",
      "in_blocks.4.attn proj_drop\n",
      "in_blocks.4.attn.qkv \n",
      "in_blocks.4.attn.attn_drop \n",
      "in_blocks.4.attn.proj \n",
      "in_blocks.4.attn.proj_drop \n",
      "in_blocks.4.drop_path \n",
      "in_blocks.4.norm3 \n",
      "in_blocks.4.mlp \n",
      "in_blocks.4.mlp fc1\n",
      "in_blocks.4.mlp act\n",
      "in_blocks.4.mlp fc2\n",
      "in_blocks.4.mlp drop\n",
      "in_blocks.4.mlp.fc1 \n",
      "in_blocks.4.mlp.act \n",
      "in_blocks.4.mlp.fc2 \n",
      "in_blocks.4.mlp.drop \n",
      "in_blocks.5 \n",
      "in_blocks.5 norm2\n",
      "in_blocks.5 attn\n",
      "in_blocks.5 attn.qkv\n",
      "in_blocks.5 attn.attn_drop\n",
      "in_blocks.5 attn.proj\n",
      "in_blocks.5 attn.proj_drop\n",
      "in_blocks.5 drop_path\n",
      "in_blocks.5 norm3\n",
      "in_blocks.5 mlp\n",
      "in_blocks.5 mlp.fc1\n",
      "in_blocks.5 mlp.act\n",
      "in_blocks.5 mlp.fc2\n",
      "in_blocks.5 mlp.drop\n",
      "in_blocks.5.norm2 \n",
      "in_blocks.5.attn \n",
      "in_blocks.5.attn qkv\n",
      "in_blocks.5.attn attn_drop\n",
      "in_blocks.5.attn proj\n",
      "in_blocks.5.attn proj_drop\n",
      "in_blocks.5.attn.qkv \n",
      "in_blocks.5.attn.attn_drop \n",
      "in_blocks.5.attn.proj \n",
      "in_blocks.5.attn.proj_drop \n",
      "in_blocks.5.drop_path \n",
      "in_blocks.5.norm3 \n",
      "in_blocks.5.mlp \n",
      "in_blocks.5.mlp fc1\n",
      "in_blocks.5.mlp act\n",
      "in_blocks.5.mlp fc2\n",
      "in_blocks.5.mlp drop\n",
      "in_blocks.5.mlp.fc1 \n",
      "in_blocks.5.mlp.act \n",
      "in_blocks.5.mlp.fc2 \n",
      "in_blocks.5.mlp.drop \n",
      "in_blocks.6 \n",
      "in_blocks.6 norm2\n",
      "in_blocks.6 attn\n",
      "in_blocks.6 attn.qkv\n",
      "in_blocks.6 attn.attn_drop\n",
      "in_blocks.6 attn.proj\n",
      "in_blocks.6 attn.proj_drop\n",
      "in_blocks.6 drop_path\n",
      "in_blocks.6 norm3\n",
      "in_blocks.6 mlp\n",
      "in_blocks.6 mlp.fc1\n",
      "in_blocks.6 mlp.act\n",
      "in_blocks.6 mlp.fc2\n",
      "in_blocks.6 mlp.drop\n",
      "in_blocks.6.norm2 \n",
      "in_blocks.6.attn \n",
      "in_blocks.6.attn qkv\n",
      "in_blocks.6.attn attn_drop\n",
      "in_blocks.6.attn proj\n",
      "in_blocks.6.attn proj_drop\n",
      "in_blocks.6.attn.qkv \n",
      "in_blocks.6.attn.attn_drop \n",
      "in_blocks.6.attn.proj \n",
      "in_blocks.6.attn.proj_drop \n",
      "in_blocks.6.drop_path \n",
      "in_blocks.6.norm3 \n",
      "in_blocks.6.mlp \n",
      "in_blocks.6.mlp fc1\n",
      "in_blocks.6.mlp act\n",
      "in_blocks.6.mlp fc2\n",
      "in_blocks.6.mlp drop\n",
      "in_blocks.6.mlp.fc1 \n",
      "in_blocks.6.mlp.act \n",
      "in_blocks.6.mlp.fc2 \n",
      "in_blocks.6.mlp.drop \n",
      "in_blocks.7 \n",
      "in_blocks.7 norm2\n",
      "in_blocks.7 attn\n",
      "in_blocks.7 attn.qkv\n",
      "in_blocks.7 attn.attn_drop\n",
      "in_blocks.7 attn.proj\n",
      "in_blocks.7 attn.proj_drop\n",
      "in_blocks.7 drop_path\n",
      "in_blocks.7 norm3\n",
      "in_blocks.7 mlp\n",
      "in_blocks.7 mlp.fc1\n",
      "in_blocks.7 mlp.act\n",
      "in_blocks.7 mlp.fc2\n",
      "in_blocks.7 mlp.drop\n",
      "in_blocks.7.norm2 \n",
      "in_blocks.7.attn \n",
      "in_blocks.7.attn qkv\n",
      "in_blocks.7.attn attn_drop\n",
      "in_blocks.7.attn proj\n",
      "in_blocks.7.attn proj_drop\n",
      "in_blocks.7.attn.qkv \n",
      "in_blocks.7.attn.attn_drop \n",
      "in_blocks.7.attn.proj \n",
      "in_blocks.7.attn.proj_drop \n",
      "in_blocks.7.drop_path \n",
      "in_blocks.7.norm3 \n",
      "in_blocks.7.mlp \n",
      "in_blocks.7.mlp fc1\n",
      "in_blocks.7.mlp act\n",
      "in_blocks.7.mlp fc2\n",
      "in_blocks.7.mlp drop\n",
      "in_blocks.7.mlp.fc1 \n",
      "in_blocks.7.mlp.act \n",
      "in_blocks.7.mlp.fc2 \n",
      "in_blocks.7.mlp.drop \n",
      "in_blocks.8 \n",
      "in_blocks.8 norm2\n",
      "in_blocks.8 attn\n",
      "in_blocks.8 attn.qkv\n",
      "in_blocks.8 attn.attn_drop\n",
      "in_blocks.8 attn.proj\n",
      "in_blocks.8 attn.proj_drop\n",
      "in_blocks.8 drop_path\n",
      "in_blocks.8 norm3\n",
      "in_blocks.8 mlp\n",
      "in_blocks.8 mlp.fc1\n",
      "in_blocks.8 mlp.act\n",
      "in_blocks.8 mlp.fc2\n",
      "in_blocks.8 mlp.drop\n",
      "in_blocks.8.norm2 \n",
      "in_blocks.8.attn \n",
      "in_blocks.8.attn qkv\n",
      "in_blocks.8.attn attn_drop\n",
      "in_blocks.8.attn proj\n",
      "in_blocks.8.attn proj_drop\n",
      "in_blocks.8.attn.qkv \n",
      "in_blocks.8.attn.attn_drop \n",
      "in_blocks.8.attn.proj \n",
      "in_blocks.8.attn.proj_drop \n",
      "in_blocks.8.drop_path \n",
      "in_blocks.8.norm3 \n",
      "in_blocks.8.mlp \n",
      "in_blocks.8.mlp fc1\n",
      "in_blocks.8.mlp act\n",
      "in_blocks.8.mlp fc2\n",
      "in_blocks.8.mlp drop\n",
      "in_blocks.8.mlp.fc1 \n",
      "in_blocks.8.mlp.act \n",
      "in_blocks.8.mlp.fc2 \n",
      "in_blocks.8.mlp.drop \n",
      "in_blocks.9 \n",
      "in_blocks.9 norm2\n",
      "in_blocks.9 attn\n",
      "in_blocks.9 attn.qkv\n",
      "in_blocks.9 attn.attn_drop\n",
      "in_blocks.9 attn.proj\n",
      "in_blocks.9 attn.proj_drop\n",
      "in_blocks.9 drop_path\n",
      "in_blocks.9 norm3\n",
      "in_blocks.9 mlp\n",
      "in_blocks.9 mlp.fc1\n",
      "in_blocks.9 mlp.act\n",
      "in_blocks.9 mlp.fc2\n",
      "in_blocks.9 mlp.drop\n",
      "in_blocks.9.norm2 \n",
      "in_blocks.9.attn \n",
      "in_blocks.9.attn qkv\n",
      "in_blocks.9.attn attn_drop\n",
      "in_blocks.9.attn proj\n",
      "in_blocks.9.attn proj_drop\n",
      "in_blocks.9.attn.qkv \n",
      "in_blocks.9.attn.attn_drop \n",
      "in_blocks.9.attn.proj \n",
      "in_blocks.9.attn.proj_drop \n",
      "in_blocks.9.drop_path \n",
      "in_blocks.9.norm3 \n",
      "in_blocks.9.mlp \n",
      "in_blocks.9.mlp fc1\n",
      "in_blocks.9.mlp act\n",
      "in_blocks.9.mlp fc2\n",
      "in_blocks.9.mlp drop\n",
      "in_blocks.9.mlp.fc1 \n",
      "in_blocks.9.mlp.act \n",
      "in_blocks.9.mlp.fc2 \n",
      "in_blocks.9.mlp.drop \n",
      "in_blocks.10 \n",
      "in_blocks.10 norm2\n",
      "in_blocks.10 attn\n",
      "in_blocks.10 attn.qkv\n",
      "in_blocks.10 attn.attn_drop\n",
      "in_blocks.10 attn.proj\n",
      "in_blocks.10 attn.proj_drop\n",
      "in_blocks.10 drop_path\n",
      "in_blocks.10 norm3\n",
      "in_blocks.10 mlp\n",
      "in_blocks.10 mlp.fc1\n",
      "in_blocks.10 mlp.act\n",
      "in_blocks.10 mlp.fc2\n",
      "in_blocks.10 mlp.drop\n",
      "in_blocks.10.norm2 \n",
      "in_blocks.10.attn \n",
      "in_blocks.10.attn qkv\n",
      "in_blocks.10.attn attn_drop\n",
      "in_blocks.10.attn proj\n",
      "in_blocks.10.attn proj_drop\n",
      "in_blocks.10.attn.qkv \n",
      "in_blocks.10.attn.attn_drop \n",
      "in_blocks.10.attn.proj \n",
      "in_blocks.10.attn.proj_drop \n",
      "in_blocks.10.drop_path \n",
      "in_blocks.10.norm3 \n",
      "in_blocks.10.mlp \n",
      "in_blocks.10.mlp fc1\n",
      "in_blocks.10.mlp act\n",
      "in_blocks.10.mlp fc2\n",
      "in_blocks.10.mlp drop\n",
      "in_blocks.10.mlp.fc1 \n",
      "in_blocks.10.mlp.act \n",
      "in_blocks.10.mlp.fc2 \n",
      "in_blocks.10.mlp.drop \n",
      "in_blocks.11 \n",
      "in_blocks.11 norm2\n",
      "in_blocks.11 attn\n",
      "in_blocks.11 attn.qkv\n",
      "in_blocks.11 attn.attn_drop\n",
      "in_blocks.11 attn.proj\n",
      "in_blocks.11 attn.proj_drop\n",
      "in_blocks.11 drop_path\n",
      "in_blocks.11 norm3\n",
      "in_blocks.11 mlp\n",
      "in_blocks.11 mlp.fc1\n",
      "in_blocks.11 mlp.act\n",
      "in_blocks.11 mlp.fc2\n",
      "in_blocks.11 mlp.drop\n",
      "in_blocks.11.norm2 \n",
      "in_blocks.11.attn \n",
      "in_blocks.11.attn qkv\n",
      "in_blocks.11.attn attn_drop\n",
      "in_blocks.11.attn proj\n",
      "in_blocks.11.attn proj_drop\n",
      "in_blocks.11.attn.qkv \n",
      "in_blocks.11.attn.attn_drop \n",
      "in_blocks.11.attn.proj \n",
      "in_blocks.11.attn.proj_drop \n",
      "in_blocks.11.drop_path \n",
      "in_blocks.11.norm3 \n",
      "in_blocks.11.mlp \n",
      "in_blocks.11.mlp fc1\n",
      "in_blocks.11.mlp act\n",
      "in_blocks.11.mlp fc2\n",
      "in_blocks.11.mlp drop\n",
      "in_blocks.11.mlp.fc1 \n",
      "in_blocks.11.mlp.act \n",
      "in_blocks.11.mlp.fc2 \n",
      "in_blocks.11.mlp.drop \n",
      "in_blocks.12 \n",
      "in_blocks.12 norm2\n",
      "in_blocks.12 attn\n",
      "in_blocks.12 attn.qkv\n",
      "in_blocks.12 attn.attn_drop\n",
      "in_blocks.12 attn.proj\n",
      "in_blocks.12 attn.proj_drop\n",
      "in_blocks.12 drop_path\n",
      "in_blocks.12 norm3\n",
      "in_blocks.12 mlp\n",
      "in_blocks.12 mlp.fc1\n",
      "in_blocks.12 mlp.act\n",
      "in_blocks.12 mlp.fc2\n",
      "in_blocks.12 mlp.drop\n",
      "in_blocks.12.norm2 \n",
      "in_blocks.12.attn \n",
      "in_blocks.12.attn qkv\n",
      "in_blocks.12.attn attn_drop\n",
      "in_blocks.12.attn proj\n",
      "in_blocks.12.attn proj_drop\n",
      "in_blocks.12.attn.qkv \n",
      "in_blocks.12.attn.attn_drop \n",
      "in_blocks.12.attn.proj \n",
      "in_blocks.12.attn.proj_drop \n",
      "in_blocks.12.drop_path \n",
      "in_blocks.12.norm3 \n",
      "in_blocks.12.mlp \n",
      "in_blocks.12.mlp fc1\n",
      "in_blocks.12.mlp act\n",
      "in_blocks.12.mlp fc2\n",
      "in_blocks.12.mlp drop\n",
      "in_blocks.12.mlp.fc1 \n",
      "in_blocks.12.mlp.act \n",
      "in_blocks.12.mlp.fc2 \n",
      "in_blocks.12.mlp.drop \n",
      "in_blocks.13 \n",
      "in_blocks.13 norm2\n",
      "in_blocks.13 attn\n",
      "in_blocks.13 attn.qkv\n",
      "in_blocks.13 attn.attn_drop\n",
      "in_blocks.13 attn.proj\n",
      "in_blocks.13 attn.proj_drop\n",
      "in_blocks.13 drop_path\n",
      "in_blocks.13 norm3\n",
      "in_blocks.13 mlp\n",
      "in_blocks.13 mlp.fc1\n",
      "in_blocks.13 mlp.act\n",
      "in_blocks.13 mlp.fc2\n",
      "in_blocks.13 mlp.drop\n",
      "in_blocks.13.norm2 \n",
      "in_blocks.13.attn \n",
      "in_blocks.13.attn qkv\n",
      "in_blocks.13.attn attn_drop\n",
      "in_blocks.13.attn proj\n",
      "in_blocks.13.attn proj_drop\n",
      "in_blocks.13.attn.qkv \n",
      "in_blocks.13.attn.attn_drop \n",
      "in_blocks.13.attn.proj \n",
      "in_blocks.13.attn.proj_drop \n",
      "in_blocks.13.drop_path \n",
      "in_blocks.13.norm3 \n",
      "in_blocks.13.mlp \n",
      "in_blocks.13.mlp fc1\n",
      "in_blocks.13.mlp act\n",
      "in_blocks.13.mlp fc2\n",
      "in_blocks.13.mlp drop\n",
      "in_blocks.13.mlp.fc1 \n",
      "in_blocks.13.mlp.act \n",
      "in_blocks.13.mlp.fc2 \n",
      "in_blocks.13.mlp.drop \n",
      "in_blocks.14 \n",
      "in_blocks.14 norm2\n",
      "in_blocks.14 attn\n",
      "in_blocks.14 attn.qkv\n",
      "in_blocks.14 attn.attn_drop\n",
      "in_blocks.14 attn.proj\n",
      "in_blocks.14 attn.proj_drop\n",
      "in_blocks.14 drop_path\n",
      "in_blocks.14 norm3\n",
      "in_blocks.14 mlp\n",
      "in_blocks.14 mlp.fc1\n",
      "in_blocks.14 mlp.act\n",
      "in_blocks.14 mlp.fc2\n",
      "in_blocks.14 mlp.drop\n",
      "in_blocks.14.norm2 \n",
      "in_blocks.14.attn \n",
      "in_blocks.14.attn qkv\n",
      "in_blocks.14.attn attn_drop\n",
      "in_blocks.14.attn proj\n",
      "in_blocks.14.attn proj_drop\n",
      "in_blocks.14.attn.qkv \n",
      "in_blocks.14.attn.attn_drop \n",
      "in_blocks.14.attn.proj \n",
      "in_blocks.14.attn.proj_drop \n",
      "in_blocks.14.drop_path \n",
      "in_blocks.14.norm3 \n",
      "in_blocks.14.mlp \n",
      "in_blocks.14.mlp fc1\n",
      "in_blocks.14.mlp act\n",
      "in_blocks.14.mlp fc2\n",
      "in_blocks.14.mlp drop\n",
      "in_blocks.14.mlp.fc1 \n",
      "in_blocks.14.mlp.act \n",
      "in_blocks.14.mlp.fc2 \n",
      "in_blocks.14.mlp.drop \n",
      "mid_block \n",
      "mid_block norm2\n",
      "mid_block attn\n",
      "mid_block attn.qkv\n",
      "mid_block attn.attn_drop\n",
      "mid_block attn.proj\n",
      "mid_block attn.proj_drop\n",
      "mid_block drop_path\n",
      "mid_block norm3\n",
      "mid_block mlp\n",
      "mid_block mlp.fc1\n",
      "mid_block mlp.act\n",
      "mid_block mlp.fc2\n",
      "mid_block mlp.drop\n",
      "mid_block.norm2 \n",
      "mid_block.attn \n",
      "mid_block.attn qkv\n",
      "mid_block.attn attn_drop\n",
      "mid_block.attn proj\n",
      "mid_block.attn proj_drop\n",
      "mid_block.attn.qkv \n",
      "mid_block.attn.attn_drop \n",
      "mid_block.attn.proj \n",
      "mid_block.attn.proj_drop \n",
      "mid_block.drop_path \n",
      "mid_block.norm3 \n",
      "mid_block.mlp \n",
      "mid_block.mlp fc1\n",
      "mid_block.mlp act\n",
      "mid_block.mlp fc2\n",
      "mid_block.mlp drop\n",
      "mid_block.mlp.fc1 \n",
      "mid_block.mlp.act \n",
      "mid_block.mlp.fc2 \n",
      "mid_block.mlp.drop \n",
      "out_blocks \n",
      "out_blocks 0\n",
      "out_blocks 0.norm1\n",
      "out_blocks 0.norm2\n",
      "out_blocks 0.attn\n",
      "out_blocks 0.attn.qkv\n",
      "out_blocks 0.attn.attn_drop\n",
      "out_blocks 0.attn.proj\n",
      "out_blocks 0.attn.proj_drop\n",
      "out_blocks 0.drop_path\n",
      "out_blocks 0.norm3\n",
      "out_blocks 0.mlp\n",
      "out_blocks 0.mlp.fc1\n",
      "out_blocks 0.mlp.act\n",
      "out_blocks 0.mlp.fc2\n",
      "out_blocks 0.mlp.drop\n",
      "out_blocks 0.skip_linear\n",
      "out_blocks 1\n",
      "out_blocks 1.norm1\n",
      "out_blocks 1.norm2\n",
      "out_blocks 1.attn\n",
      "out_blocks 1.attn.qkv\n",
      "out_blocks 1.attn.attn_drop\n",
      "out_blocks 1.attn.proj\n",
      "out_blocks 1.attn.proj_drop\n",
      "out_blocks 1.drop_path\n",
      "out_blocks 1.norm3\n",
      "out_blocks 1.mlp\n",
      "out_blocks 1.mlp.fc1\n",
      "out_blocks 1.mlp.act\n",
      "out_blocks 1.mlp.fc2\n",
      "out_blocks 1.mlp.drop\n",
      "out_blocks 1.skip_linear\n",
      "out_blocks 2\n",
      "out_blocks 2.norm1\n",
      "out_blocks 2.norm2\n",
      "out_blocks 2.attn\n",
      "out_blocks 2.attn.qkv\n",
      "out_blocks 2.attn.attn_drop\n",
      "out_blocks 2.attn.proj\n",
      "out_blocks 2.attn.proj_drop\n",
      "out_blocks 2.drop_path\n",
      "out_blocks 2.norm3\n",
      "out_blocks 2.mlp\n",
      "out_blocks 2.mlp.fc1\n",
      "out_blocks 2.mlp.act\n",
      "out_blocks 2.mlp.fc2\n",
      "out_blocks 2.mlp.drop\n",
      "out_blocks 2.skip_linear\n",
      "out_blocks 3\n",
      "out_blocks 3.norm1\n",
      "out_blocks 3.norm2\n",
      "out_blocks 3.attn\n",
      "out_blocks 3.attn.qkv\n",
      "out_blocks 3.attn.attn_drop\n",
      "out_blocks 3.attn.proj\n",
      "out_blocks 3.attn.proj_drop\n",
      "out_blocks 3.drop_path\n",
      "out_blocks 3.norm3\n",
      "out_blocks 3.mlp\n",
      "out_blocks 3.mlp.fc1\n",
      "out_blocks 3.mlp.act\n",
      "out_blocks 3.mlp.fc2\n",
      "out_blocks 3.mlp.drop\n",
      "out_blocks 3.skip_linear\n",
      "out_blocks 4\n",
      "out_blocks 4.norm1\n",
      "out_blocks 4.norm2\n",
      "out_blocks 4.attn\n",
      "out_blocks 4.attn.qkv\n",
      "out_blocks 4.attn.attn_drop\n",
      "out_blocks 4.attn.proj\n",
      "out_blocks 4.attn.proj_drop\n",
      "out_blocks 4.drop_path\n",
      "out_blocks 4.norm3\n",
      "out_blocks 4.mlp\n",
      "out_blocks 4.mlp.fc1\n",
      "out_blocks 4.mlp.act\n",
      "out_blocks 4.mlp.fc2\n",
      "out_blocks 4.mlp.drop\n",
      "out_blocks 4.skip_linear\n",
      "out_blocks 5\n",
      "out_blocks 5.norm1\n",
      "out_blocks 5.norm2\n",
      "out_blocks 5.attn\n",
      "out_blocks 5.attn.qkv\n",
      "out_blocks 5.attn.attn_drop\n",
      "out_blocks 5.attn.proj\n",
      "out_blocks 5.attn.proj_drop\n",
      "out_blocks 5.drop_path\n",
      "out_blocks 5.norm3\n",
      "out_blocks 5.mlp\n",
      "out_blocks 5.mlp.fc1\n",
      "out_blocks 5.mlp.act\n",
      "out_blocks 5.mlp.fc2\n",
      "out_blocks 5.mlp.drop\n",
      "out_blocks 5.skip_linear\n",
      "out_blocks 6\n",
      "out_blocks 6.norm1\n",
      "out_blocks 6.norm2\n",
      "out_blocks 6.attn\n",
      "out_blocks 6.attn.qkv\n",
      "out_blocks 6.attn.attn_drop\n",
      "out_blocks 6.attn.proj\n",
      "out_blocks 6.attn.proj_drop\n",
      "out_blocks 6.drop_path\n",
      "out_blocks 6.norm3\n",
      "out_blocks 6.mlp\n",
      "out_blocks 6.mlp.fc1\n",
      "out_blocks 6.mlp.act\n",
      "out_blocks 6.mlp.fc2\n",
      "out_blocks 6.mlp.drop\n",
      "out_blocks 6.skip_linear\n",
      "out_blocks 7\n",
      "out_blocks 7.norm1\n",
      "out_blocks 7.norm2\n",
      "out_blocks 7.attn\n",
      "out_blocks 7.attn.qkv\n",
      "out_blocks 7.attn.attn_drop\n",
      "out_blocks 7.attn.proj\n",
      "out_blocks 7.attn.proj_drop\n",
      "out_blocks 7.drop_path\n",
      "out_blocks 7.norm3\n",
      "out_blocks 7.mlp\n",
      "out_blocks 7.mlp.fc1\n",
      "out_blocks 7.mlp.act\n",
      "out_blocks 7.mlp.fc2\n",
      "out_blocks 7.mlp.drop\n",
      "out_blocks 7.skip_linear\n",
      "out_blocks 8\n",
      "out_blocks 8.norm1\n",
      "out_blocks 8.norm2\n",
      "out_blocks 8.attn\n",
      "out_blocks 8.attn.qkv\n",
      "out_blocks 8.attn.attn_drop\n",
      "out_blocks 8.attn.proj\n",
      "out_blocks 8.attn.proj_drop\n",
      "out_blocks 8.drop_path\n",
      "out_blocks 8.norm3\n",
      "out_blocks 8.mlp\n",
      "out_blocks 8.mlp.fc1\n",
      "out_blocks 8.mlp.act\n",
      "out_blocks 8.mlp.fc2\n",
      "out_blocks 8.mlp.drop\n",
      "out_blocks 8.skip_linear\n",
      "out_blocks 9\n",
      "out_blocks 9.norm1\n",
      "out_blocks 9.norm2\n",
      "out_blocks 9.attn\n",
      "out_blocks 9.attn.qkv\n",
      "out_blocks 9.attn.attn_drop\n",
      "out_blocks 9.attn.proj\n",
      "out_blocks 9.attn.proj_drop\n",
      "out_blocks 9.drop_path\n",
      "out_blocks 9.norm3\n",
      "out_blocks 9.mlp\n",
      "out_blocks 9.mlp.fc1\n",
      "out_blocks 9.mlp.act\n",
      "out_blocks 9.mlp.fc2\n",
      "out_blocks 9.mlp.drop\n",
      "out_blocks 9.skip_linear\n",
      "out_blocks 10\n",
      "out_blocks 10.norm1\n",
      "out_blocks 10.norm2\n",
      "out_blocks 10.attn\n",
      "out_blocks 10.attn.qkv\n",
      "out_blocks 10.attn.attn_drop\n",
      "out_blocks 10.attn.proj\n",
      "out_blocks 10.attn.proj_drop\n",
      "out_blocks 10.drop_path\n",
      "out_blocks 10.norm3\n",
      "out_blocks 10.mlp\n",
      "out_blocks 10.mlp.fc1\n",
      "out_blocks 10.mlp.act\n",
      "out_blocks 10.mlp.fc2\n",
      "out_blocks 10.mlp.drop\n",
      "out_blocks 10.skip_linear\n",
      "out_blocks 11\n",
      "out_blocks 11.norm1\n",
      "out_blocks 11.norm2\n",
      "out_blocks 11.attn\n",
      "out_blocks 11.attn.qkv\n",
      "out_blocks 11.attn.attn_drop\n",
      "out_blocks 11.attn.proj\n",
      "out_blocks 11.attn.proj_drop\n",
      "out_blocks 11.drop_path\n",
      "out_blocks 11.norm3\n",
      "out_blocks 11.mlp\n",
      "out_blocks 11.mlp.fc1\n",
      "out_blocks 11.mlp.act\n",
      "out_blocks 11.mlp.fc2\n",
      "out_blocks 11.mlp.drop\n",
      "out_blocks 11.skip_linear\n",
      "out_blocks 12\n",
      "out_blocks 12.norm1\n",
      "out_blocks 12.norm2\n",
      "out_blocks 12.attn\n",
      "out_blocks 12.attn.qkv\n",
      "out_blocks 12.attn.attn_drop\n",
      "out_blocks 12.attn.proj\n",
      "out_blocks 12.attn.proj_drop\n",
      "out_blocks 12.drop_path\n",
      "out_blocks 12.norm3\n",
      "out_blocks 12.mlp\n",
      "out_blocks 12.mlp.fc1\n",
      "out_blocks 12.mlp.act\n",
      "out_blocks 12.mlp.fc2\n",
      "out_blocks 12.mlp.drop\n",
      "out_blocks 12.skip_linear\n",
      "out_blocks 13\n",
      "out_blocks 13.norm1\n",
      "out_blocks 13.norm2\n",
      "out_blocks 13.attn\n",
      "out_blocks 13.attn.qkv\n",
      "out_blocks 13.attn.attn_drop\n",
      "out_blocks 13.attn.proj\n",
      "out_blocks 13.attn.proj_drop\n",
      "out_blocks 13.drop_path\n",
      "out_blocks 13.norm3\n",
      "out_blocks 13.mlp\n",
      "out_blocks 13.mlp.fc1\n",
      "out_blocks 13.mlp.act\n",
      "out_blocks 13.mlp.fc2\n",
      "out_blocks 13.mlp.drop\n",
      "out_blocks 13.skip_linear\n",
      "out_blocks 14\n",
      "out_blocks 14.norm1\n",
      "out_blocks 14.norm2\n",
      "out_blocks 14.attn\n",
      "out_blocks 14.attn.qkv\n",
      "out_blocks 14.attn.attn_drop\n",
      "out_blocks 14.attn.proj\n",
      "out_blocks 14.attn.proj_drop\n",
      "out_blocks 14.drop_path\n",
      "out_blocks 14.norm3\n",
      "out_blocks 14.mlp\n",
      "out_blocks 14.mlp.fc1\n",
      "out_blocks 14.mlp.act\n",
      "out_blocks 14.mlp.fc2\n",
      "out_blocks 14.mlp.drop\n",
      "out_blocks 14.skip_linear\n",
      "out_blocks.0 \n",
      "out_blocks.0 norm1\n",
      "out_blocks.0 norm2\n",
      "out_blocks.0 attn\n",
      "out_blocks.0 attn.qkv\n",
      "out_blocks.0 attn.attn_drop\n",
      "out_blocks.0 attn.proj\n",
      "out_blocks.0 attn.proj_drop\n",
      "out_blocks.0 drop_path\n",
      "out_blocks.0 norm3\n",
      "out_blocks.0 mlp\n",
      "out_blocks.0 mlp.fc1\n",
      "out_blocks.0 mlp.act\n",
      "out_blocks.0 mlp.fc2\n",
      "out_blocks.0 mlp.drop\n",
      "out_blocks.0 skip_linear\n",
      "out_blocks.0.norm1 \n",
      "out_blocks.0.norm2 \n",
      "out_blocks.0.attn \n",
      "out_blocks.0.attn qkv\n",
      "out_blocks.0.attn attn_drop\n",
      "out_blocks.0.attn proj\n",
      "out_blocks.0.attn proj_drop\n",
      "out_blocks.0.attn.qkv \n",
      "out_blocks.0.attn.attn_drop \n",
      "out_blocks.0.attn.proj \n",
      "out_blocks.0.attn.proj_drop \n",
      "out_blocks.0.drop_path \n",
      "out_blocks.0.norm3 \n",
      "out_blocks.0.mlp \n",
      "out_blocks.0.mlp fc1\n",
      "out_blocks.0.mlp act\n",
      "out_blocks.0.mlp fc2\n",
      "out_blocks.0.mlp drop\n",
      "out_blocks.0.mlp.fc1 \n",
      "out_blocks.0.mlp.act \n",
      "out_blocks.0.mlp.fc2 \n",
      "out_blocks.0.mlp.drop \n",
      "out_blocks.0.skip_linear \n",
      "out_blocks.1 \n",
      "out_blocks.1 norm1\n",
      "out_blocks.1 norm2\n",
      "out_blocks.1 attn\n",
      "out_blocks.1 attn.qkv\n",
      "out_blocks.1 attn.attn_drop\n",
      "out_blocks.1 attn.proj\n",
      "out_blocks.1 attn.proj_drop\n",
      "out_blocks.1 drop_path\n",
      "out_blocks.1 norm3\n",
      "out_blocks.1 mlp\n",
      "out_blocks.1 mlp.fc1\n",
      "out_blocks.1 mlp.act\n",
      "out_blocks.1 mlp.fc2\n",
      "out_blocks.1 mlp.drop\n",
      "out_blocks.1 skip_linear\n",
      "out_blocks.1.norm1 \n",
      "out_blocks.1.norm2 \n",
      "out_blocks.1.attn \n",
      "out_blocks.1.attn qkv\n",
      "out_blocks.1.attn attn_drop\n",
      "out_blocks.1.attn proj\n",
      "out_blocks.1.attn proj_drop\n",
      "out_blocks.1.attn.qkv \n",
      "out_blocks.1.attn.attn_drop \n",
      "out_blocks.1.attn.proj \n",
      "out_blocks.1.attn.proj_drop \n",
      "out_blocks.1.drop_path \n",
      "out_blocks.1.norm3 \n",
      "out_blocks.1.mlp \n",
      "out_blocks.1.mlp fc1\n",
      "out_blocks.1.mlp act\n",
      "out_blocks.1.mlp fc2\n",
      "out_blocks.1.mlp drop\n",
      "out_blocks.1.mlp.fc1 \n",
      "out_blocks.1.mlp.act \n",
      "out_blocks.1.mlp.fc2 \n",
      "out_blocks.1.mlp.drop \n",
      "out_blocks.1.skip_linear \n",
      "out_blocks.2 \n",
      "out_blocks.2 norm1\n",
      "out_blocks.2 norm2\n",
      "out_blocks.2 attn\n",
      "out_blocks.2 attn.qkv\n",
      "out_blocks.2 attn.attn_drop\n",
      "out_blocks.2 attn.proj\n",
      "out_blocks.2 attn.proj_drop\n",
      "out_blocks.2 drop_path\n",
      "out_blocks.2 norm3\n",
      "out_blocks.2 mlp\n",
      "out_blocks.2 mlp.fc1\n",
      "out_blocks.2 mlp.act\n",
      "out_blocks.2 mlp.fc2\n",
      "out_blocks.2 mlp.drop\n",
      "out_blocks.2 skip_linear\n",
      "out_blocks.2.norm1 \n",
      "out_blocks.2.norm2 \n",
      "out_blocks.2.attn \n",
      "out_blocks.2.attn qkv\n",
      "out_blocks.2.attn attn_drop\n",
      "out_blocks.2.attn proj\n",
      "out_blocks.2.attn proj_drop\n",
      "out_blocks.2.attn.qkv \n",
      "out_blocks.2.attn.attn_drop \n",
      "out_blocks.2.attn.proj \n",
      "out_blocks.2.attn.proj_drop \n",
      "out_blocks.2.drop_path \n",
      "out_blocks.2.norm3 \n",
      "out_blocks.2.mlp \n",
      "out_blocks.2.mlp fc1\n",
      "out_blocks.2.mlp act\n",
      "out_blocks.2.mlp fc2\n",
      "out_blocks.2.mlp drop\n",
      "out_blocks.2.mlp.fc1 \n",
      "out_blocks.2.mlp.act \n",
      "out_blocks.2.mlp.fc2 \n",
      "out_blocks.2.mlp.drop \n",
      "out_blocks.2.skip_linear \n",
      "out_blocks.3 \n",
      "out_blocks.3 norm1\n",
      "out_blocks.3 norm2\n",
      "out_blocks.3 attn\n",
      "out_blocks.3 attn.qkv\n",
      "out_blocks.3 attn.attn_drop\n",
      "out_blocks.3 attn.proj\n",
      "out_blocks.3 attn.proj_drop\n",
      "out_blocks.3 drop_path\n",
      "out_blocks.3 norm3\n",
      "out_blocks.3 mlp\n",
      "out_blocks.3 mlp.fc1\n",
      "out_blocks.3 mlp.act\n",
      "out_blocks.3 mlp.fc2\n",
      "out_blocks.3 mlp.drop\n",
      "out_blocks.3 skip_linear\n",
      "out_blocks.3.norm1 \n",
      "out_blocks.3.norm2 \n",
      "out_blocks.3.attn \n",
      "out_blocks.3.attn qkv\n",
      "out_blocks.3.attn attn_drop\n",
      "out_blocks.3.attn proj\n",
      "out_blocks.3.attn proj_drop\n",
      "out_blocks.3.attn.qkv \n",
      "out_blocks.3.attn.attn_drop \n",
      "out_blocks.3.attn.proj \n",
      "out_blocks.3.attn.proj_drop \n",
      "out_blocks.3.drop_path \n",
      "out_blocks.3.norm3 \n",
      "out_blocks.3.mlp \n",
      "out_blocks.3.mlp fc1\n",
      "out_blocks.3.mlp act\n",
      "out_blocks.3.mlp fc2\n",
      "out_blocks.3.mlp drop\n",
      "out_blocks.3.mlp.fc1 \n",
      "out_blocks.3.mlp.act \n",
      "out_blocks.3.mlp.fc2 \n",
      "out_blocks.3.mlp.drop \n",
      "out_blocks.3.skip_linear \n",
      "out_blocks.4 \n",
      "out_blocks.4 norm1\n",
      "out_blocks.4 norm2\n",
      "out_blocks.4 attn\n",
      "out_blocks.4 attn.qkv\n",
      "out_blocks.4 attn.attn_drop\n",
      "out_blocks.4 attn.proj\n",
      "out_blocks.4 attn.proj_drop\n",
      "out_blocks.4 drop_path\n",
      "out_blocks.4 norm3\n",
      "out_blocks.4 mlp\n",
      "out_blocks.4 mlp.fc1\n",
      "out_blocks.4 mlp.act\n",
      "out_blocks.4 mlp.fc2\n",
      "out_blocks.4 mlp.drop\n",
      "out_blocks.4 skip_linear\n",
      "out_blocks.4.norm1 \n",
      "out_blocks.4.norm2 \n",
      "out_blocks.4.attn \n",
      "out_blocks.4.attn qkv\n",
      "out_blocks.4.attn attn_drop\n",
      "out_blocks.4.attn proj\n",
      "out_blocks.4.attn proj_drop\n",
      "out_blocks.4.attn.qkv \n",
      "out_blocks.4.attn.attn_drop \n",
      "out_blocks.4.attn.proj \n",
      "out_blocks.4.attn.proj_drop \n",
      "out_blocks.4.drop_path \n",
      "out_blocks.4.norm3 \n",
      "out_blocks.4.mlp \n",
      "out_blocks.4.mlp fc1\n",
      "out_blocks.4.mlp act\n",
      "out_blocks.4.mlp fc2\n",
      "out_blocks.4.mlp drop\n",
      "out_blocks.4.mlp.fc1 \n",
      "out_blocks.4.mlp.act \n",
      "out_blocks.4.mlp.fc2 \n",
      "out_blocks.4.mlp.drop \n",
      "out_blocks.4.skip_linear \n",
      "out_blocks.5 \n",
      "out_blocks.5 norm1\n",
      "out_blocks.5 norm2\n",
      "out_blocks.5 attn\n",
      "out_blocks.5 attn.qkv\n",
      "out_blocks.5 attn.attn_drop\n",
      "out_blocks.5 attn.proj\n",
      "out_blocks.5 attn.proj_drop\n",
      "out_blocks.5 drop_path\n",
      "out_blocks.5 norm3\n",
      "out_blocks.5 mlp\n",
      "out_blocks.5 mlp.fc1\n",
      "out_blocks.5 mlp.act\n",
      "out_blocks.5 mlp.fc2\n",
      "out_blocks.5 mlp.drop\n",
      "out_blocks.5 skip_linear\n",
      "out_blocks.5.norm1 \n",
      "out_blocks.5.norm2 \n",
      "out_blocks.5.attn \n",
      "out_blocks.5.attn qkv\n",
      "out_blocks.5.attn attn_drop\n",
      "out_blocks.5.attn proj\n",
      "out_blocks.5.attn proj_drop\n",
      "out_blocks.5.attn.qkv \n",
      "out_blocks.5.attn.attn_drop \n",
      "out_blocks.5.attn.proj \n",
      "out_blocks.5.attn.proj_drop \n",
      "out_blocks.5.drop_path \n",
      "out_blocks.5.norm3 \n",
      "out_blocks.5.mlp \n",
      "out_blocks.5.mlp fc1\n",
      "out_blocks.5.mlp act\n",
      "out_blocks.5.mlp fc2\n",
      "out_blocks.5.mlp drop\n",
      "out_blocks.5.mlp.fc1 \n",
      "out_blocks.5.mlp.act \n",
      "out_blocks.5.mlp.fc2 \n",
      "out_blocks.5.mlp.drop \n",
      "out_blocks.5.skip_linear \n",
      "out_blocks.6 \n",
      "out_blocks.6 norm1\n",
      "out_blocks.6 norm2\n",
      "out_blocks.6 attn\n",
      "out_blocks.6 attn.qkv\n",
      "out_blocks.6 attn.attn_drop\n",
      "out_blocks.6 attn.proj\n",
      "out_blocks.6 attn.proj_drop\n",
      "out_blocks.6 drop_path\n",
      "out_blocks.6 norm3\n",
      "out_blocks.6 mlp\n",
      "out_blocks.6 mlp.fc1\n",
      "out_blocks.6 mlp.act\n",
      "out_blocks.6 mlp.fc2\n",
      "out_blocks.6 mlp.drop\n",
      "out_blocks.6 skip_linear\n",
      "out_blocks.6.norm1 \n",
      "out_blocks.6.norm2 \n",
      "out_blocks.6.attn \n",
      "out_blocks.6.attn qkv\n",
      "out_blocks.6.attn attn_drop\n",
      "out_blocks.6.attn proj\n",
      "out_blocks.6.attn proj_drop\n",
      "out_blocks.6.attn.qkv \n",
      "out_blocks.6.attn.attn_drop \n",
      "out_blocks.6.attn.proj \n",
      "out_blocks.6.attn.proj_drop \n",
      "out_blocks.6.drop_path \n",
      "out_blocks.6.norm3 \n",
      "out_blocks.6.mlp \n",
      "out_blocks.6.mlp fc1\n",
      "out_blocks.6.mlp act\n",
      "out_blocks.6.mlp fc2\n",
      "out_blocks.6.mlp drop\n",
      "out_blocks.6.mlp.fc1 \n",
      "out_blocks.6.mlp.act \n",
      "out_blocks.6.mlp.fc2 \n",
      "out_blocks.6.mlp.drop \n",
      "out_blocks.6.skip_linear \n",
      "out_blocks.7 \n",
      "out_blocks.7 norm1\n",
      "out_blocks.7 norm2\n",
      "out_blocks.7 attn\n",
      "out_blocks.7 attn.qkv\n",
      "out_blocks.7 attn.attn_drop\n",
      "out_blocks.7 attn.proj\n",
      "out_blocks.7 attn.proj_drop\n",
      "out_blocks.7 drop_path\n",
      "out_blocks.7 norm3\n",
      "out_blocks.7 mlp\n",
      "out_blocks.7 mlp.fc1\n",
      "out_blocks.7 mlp.act\n",
      "out_blocks.7 mlp.fc2\n",
      "out_blocks.7 mlp.drop\n",
      "out_blocks.7 skip_linear\n",
      "out_blocks.7.norm1 \n",
      "out_blocks.7.norm2 \n",
      "out_blocks.7.attn \n",
      "out_blocks.7.attn qkv\n",
      "out_blocks.7.attn attn_drop\n",
      "out_blocks.7.attn proj\n",
      "out_blocks.7.attn proj_drop\n",
      "out_blocks.7.attn.qkv \n",
      "out_blocks.7.attn.attn_drop \n",
      "out_blocks.7.attn.proj \n",
      "out_blocks.7.attn.proj_drop \n",
      "out_blocks.7.drop_path \n",
      "out_blocks.7.norm3 \n",
      "out_blocks.7.mlp \n",
      "out_blocks.7.mlp fc1\n",
      "out_blocks.7.mlp act\n",
      "out_blocks.7.mlp fc2\n",
      "out_blocks.7.mlp drop\n",
      "out_blocks.7.mlp.fc1 \n",
      "out_blocks.7.mlp.act \n",
      "out_blocks.7.mlp.fc2 \n",
      "out_blocks.7.mlp.drop \n",
      "out_blocks.7.skip_linear \n",
      "out_blocks.8 \n",
      "out_blocks.8 norm1\n",
      "out_blocks.8 norm2\n",
      "out_blocks.8 attn\n",
      "out_blocks.8 attn.qkv\n",
      "out_blocks.8 attn.attn_drop\n",
      "out_blocks.8 attn.proj\n",
      "out_blocks.8 attn.proj_drop\n",
      "out_blocks.8 drop_path\n",
      "out_blocks.8 norm3\n",
      "out_blocks.8 mlp\n",
      "out_blocks.8 mlp.fc1\n",
      "out_blocks.8 mlp.act\n",
      "out_blocks.8 mlp.fc2\n",
      "out_blocks.8 mlp.drop\n",
      "out_blocks.8 skip_linear\n",
      "out_blocks.8.norm1 \n",
      "out_blocks.8.norm2 \n",
      "out_blocks.8.attn \n",
      "out_blocks.8.attn qkv\n",
      "out_blocks.8.attn attn_drop\n",
      "out_blocks.8.attn proj\n",
      "out_blocks.8.attn proj_drop\n",
      "out_blocks.8.attn.qkv \n",
      "out_blocks.8.attn.attn_drop \n",
      "out_blocks.8.attn.proj \n",
      "out_blocks.8.attn.proj_drop \n",
      "out_blocks.8.drop_path \n",
      "out_blocks.8.norm3 \n",
      "out_blocks.8.mlp \n",
      "out_blocks.8.mlp fc1\n",
      "out_blocks.8.mlp act\n",
      "out_blocks.8.mlp fc2\n",
      "out_blocks.8.mlp drop\n",
      "out_blocks.8.mlp.fc1 \n",
      "out_blocks.8.mlp.act \n",
      "out_blocks.8.mlp.fc2 \n",
      "out_blocks.8.mlp.drop \n",
      "out_blocks.8.skip_linear \n",
      "out_blocks.9 \n",
      "out_blocks.9 norm1\n",
      "out_blocks.9 norm2\n",
      "out_blocks.9 attn\n",
      "out_blocks.9 attn.qkv\n",
      "out_blocks.9 attn.attn_drop\n",
      "out_blocks.9 attn.proj\n",
      "out_blocks.9 attn.proj_drop\n",
      "out_blocks.9 drop_path\n",
      "out_blocks.9 norm3\n",
      "out_blocks.9 mlp\n",
      "out_blocks.9 mlp.fc1\n",
      "out_blocks.9 mlp.act\n",
      "out_blocks.9 mlp.fc2\n",
      "out_blocks.9 mlp.drop\n",
      "out_blocks.9 skip_linear\n",
      "out_blocks.9.norm1 \n",
      "out_blocks.9.norm2 \n",
      "out_blocks.9.attn \n",
      "out_blocks.9.attn qkv\n",
      "out_blocks.9.attn attn_drop\n",
      "out_blocks.9.attn proj\n",
      "out_blocks.9.attn proj_drop\n",
      "out_blocks.9.attn.qkv \n",
      "out_blocks.9.attn.attn_drop \n",
      "out_blocks.9.attn.proj \n",
      "out_blocks.9.attn.proj_drop \n",
      "out_blocks.9.drop_path \n",
      "out_blocks.9.norm3 \n",
      "out_blocks.9.mlp \n",
      "out_blocks.9.mlp fc1\n",
      "out_blocks.9.mlp act\n",
      "out_blocks.9.mlp fc2\n",
      "out_blocks.9.mlp drop\n",
      "out_blocks.9.mlp.fc1 \n",
      "out_blocks.9.mlp.act \n",
      "out_blocks.9.mlp.fc2 \n",
      "out_blocks.9.mlp.drop \n",
      "out_blocks.9.skip_linear \n",
      "out_blocks.10 \n",
      "out_blocks.10 norm1\n",
      "out_blocks.10 norm2\n",
      "out_blocks.10 attn\n",
      "out_blocks.10 attn.qkv\n",
      "out_blocks.10 attn.attn_drop\n",
      "out_blocks.10 attn.proj\n",
      "out_blocks.10 attn.proj_drop\n",
      "out_blocks.10 drop_path\n",
      "out_blocks.10 norm3\n",
      "out_blocks.10 mlp\n",
      "out_blocks.10 mlp.fc1\n",
      "out_blocks.10 mlp.act\n",
      "out_blocks.10 mlp.fc2\n",
      "out_blocks.10 mlp.drop\n",
      "out_blocks.10 skip_linear\n",
      "out_blocks.10.norm1 \n",
      "out_blocks.10.norm2 \n",
      "out_blocks.10.attn \n",
      "out_blocks.10.attn qkv\n",
      "out_blocks.10.attn attn_drop\n",
      "out_blocks.10.attn proj\n",
      "out_blocks.10.attn proj_drop\n",
      "out_blocks.10.attn.qkv \n",
      "out_blocks.10.attn.attn_drop \n",
      "out_blocks.10.attn.proj \n",
      "out_blocks.10.attn.proj_drop \n",
      "out_blocks.10.drop_path \n",
      "out_blocks.10.norm3 \n",
      "out_blocks.10.mlp \n",
      "out_blocks.10.mlp fc1\n",
      "out_blocks.10.mlp act\n",
      "out_blocks.10.mlp fc2\n",
      "out_blocks.10.mlp drop\n",
      "out_blocks.10.mlp.fc1 \n",
      "out_blocks.10.mlp.act \n",
      "out_blocks.10.mlp.fc2 \n",
      "out_blocks.10.mlp.drop \n",
      "out_blocks.10.skip_linear \n",
      "out_blocks.11 \n",
      "out_blocks.11 norm1\n",
      "out_blocks.11 norm2\n",
      "out_blocks.11 attn\n",
      "out_blocks.11 attn.qkv\n",
      "out_blocks.11 attn.attn_drop\n",
      "out_blocks.11 attn.proj\n",
      "out_blocks.11 attn.proj_drop\n",
      "out_blocks.11 drop_path\n",
      "out_blocks.11 norm3\n",
      "out_blocks.11 mlp\n",
      "out_blocks.11 mlp.fc1\n",
      "out_blocks.11 mlp.act\n",
      "out_blocks.11 mlp.fc2\n",
      "out_blocks.11 mlp.drop\n",
      "out_blocks.11 skip_linear\n",
      "out_blocks.11.norm1 \n",
      "out_blocks.11.norm2 \n",
      "out_blocks.11.attn \n",
      "out_blocks.11.attn qkv\n",
      "out_blocks.11.attn attn_drop\n",
      "out_blocks.11.attn proj\n",
      "out_blocks.11.attn proj_drop\n",
      "out_blocks.11.attn.qkv \n",
      "out_blocks.11.attn.attn_drop \n",
      "out_blocks.11.attn.proj \n",
      "out_blocks.11.attn.proj_drop \n",
      "out_blocks.11.drop_path \n",
      "out_blocks.11.norm3 \n",
      "out_blocks.11.mlp \n",
      "out_blocks.11.mlp fc1\n",
      "out_blocks.11.mlp act\n",
      "out_blocks.11.mlp fc2\n",
      "out_blocks.11.mlp drop\n",
      "out_blocks.11.mlp.fc1 \n",
      "out_blocks.11.mlp.act \n",
      "out_blocks.11.mlp.fc2 \n",
      "out_blocks.11.mlp.drop \n",
      "out_blocks.11.skip_linear \n",
      "out_blocks.12 \n",
      "out_blocks.12 norm1\n",
      "out_blocks.12 norm2\n",
      "out_blocks.12 attn\n",
      "out_blocks.12 attn.qkv\n",
      "out_blocks.12 attn.attn_drop\n",
      "out_blocks.12 attn.proj\n",
      "out_blocks.12 attn.proj_drop\n",
      "out_blocks.12 drop_path\n",
      "out_blocks.12 norm3\n",
      "out_blocks.12 mlp\n",
      "out_blocks.12 mlp.fc1\n",
      "out_blocks.12 mlp.act\n",
      "out_blocks.12 mlp.fc2\n",
      "out_blocks.12 mlp.drop\n",
      "out_blocks.12 skip_linear\n",
      "out_blocks.12.norm1 \n",
      "out_blocks.12.norm2 \n",
      "out_blocks.12.attn \n",
      "out_blocks.12.attn qkv\n",
      "out_blocks.12.attn attn_drop\n",
      "out_blocks.12.attn proj\n",
      "out_blocks.12.attn proj_drop\n",
      "out_blocks.12.attn.qkv \n",
      "out_blocks.12.attn.attn_drop \n",
      "out_blocks.12.attn.proj \n",
      "out_blocks.12.attn.proj_drop \n",
      "out_blocks.12.drop_path \n",
      "out_blocks.12.norm3 \n",
      "out_blocks.12.mlp \n",
      "out_blocks.12.mlp fc1\n",
      "out_blocks.12.mlp act\n",
      "out_blocks.12.mlp fc2\n",
      "out_blocks.12.mlp drop\n",
      "out_blocks.12.mlp.fc1 \n",
      "out_blocks.12.mlp.act \n",
      "out_blocks.12.mlp.fc2 \n",
      "out_blocks.12.mlp.drop \n",
      "out_blocks.12.skip_linear \n",
      "out_blocks.13 \n",
      "out_blocks.13 norm1\n",
      "out_blocks.13 norm2\n",
      "out_blocks.13 attn\n",
      "out_blocks.13 attn.qkv\n",
      "out_blocks.13 attn.attn_drop\n",
      "out_blocks.13 attn.proj\n",
      "out_blocks.13 attn.proj_drop\n",
      "out_blocks.13 drop_path\n",
      "out_blocks.13 norm3\n",
      "out_blocks.13 mlp\n",
      "out_blocks.13 mlp.fc1\n",
      "out_blocks.13 mlp.act\n",
      "out_blocks.13 mlp.fc2\n",
      "out_blocks.13 mlp.drop\n",
      "out_blocks.13 skip_linear\n",
      "out_blocks.13.norm1 \n",
      "out_blocks.13.norm2 \n",
      "out_blocks.13.attn \n",
      "out_blocks.13.attn qkv\n",
      "out_blocks.13.attn attn_drop\n",
      "out_blocks.13.attn proj\n",
      "out_blocks.13.attn proj_drop\n",
      "out_blocks.13.attn.qkv \n",
      "out_blocks.13.attn.attn_drop \n",
      "out_blocks.13.attn.proj \n",
      "out_blocks.13.attn.proj_drop \n",
      "out_blocks.13.drop_path \n",
      "out_blocks.13.norm3 \n",
      "out_blocks.13.mlp \n",
      "out_blocks.13.mlp fc1\n",
      "out_blocks.13.mlp act\n",
      "out_blocks.13.mlp fc2\n",
      "out_blocks.13.mlp drop\n",
      "out_blocks.13.mlp.fc1 \n",
      "out_blocks.13.mlp.act \n",
      "out_blocks.13.mlp.fc2 \n",
      "out_blocks.13.mlp.drop \n",
      "out_blocks.13.skip_linear \n",
      "out_blocks.14 \n",
      "out_blocks.14 norm1\n",
      "out_blocks.14 norm2\n",
      "out_blocks.14 attn\n",
      "out_blocks.14 attn.qkv\n",
      "out_blocks.14 attn.attn_drop\n",
      "out_blocks.14 attn.proj\n",
      "out_blocks.14 attn.proj_drop\n",
      "out_blocks.14 drop_path\n",
      "out_blocks.14 norm3\n",
      "out_blocks.14 mlp\n",
      "out_blocks.14 mlp.fc1\n",
      "out_blocks.14 mlp.act\n",
      "out_blocks.14 mlp.fc2\n",
      "out_blocks.14 mlp.drop\n",
      "out_blocks.14 skip_linear\n",
      "out_blocks.14.norm1 \n",
      "out_blocks.14.norm2 \n",
      "out_blocks.14.attn \n",
      "out_blocks.14.attn qkv\n",
      "out_blocks.14.attn attn_drop\n",
      "out_blocks.14.attn proj\n",
      "out_blocks.14.attn proj_drop\n",
      "out_blocks.14.attn.qkv \n",
      "out_blocks.14.attn.attn_drop \n",
      "out_blocks.14.attn.proj \n",
      "out_blocks.14.attn.proj_drop \n",
      "out_blocks.14.drop_path \n",
      "out_blocks.14.norm3 \n",
      "out_blocks.14.mlp \n",
      "out_blocks.14.mlp fc1\n",
      "out_blocks.14.mlp act\n",
      "out_blocks.14.mlp fc2\n",
      "out_blocks.14.mlp drop\n",
      "out_blocks.14.mlp.fc1 \n",
      "out_blocks.14.mlp.act \n",
      "out_blocks.14.mlp.fc2 \n",
      "out_blocks.14.mlp.drop \n",
      "out_blocks.14.skip_linear \n",
      "norm \n",
      "decoder_pred \n",
      "token_embedding \n"
     ]
    }
   ],
   "source": [
    "for name, module in train_state.nnet.named_modules():\n",
    "    for child_name, child_module in module.named_modules():\n",
    "        print(name, child_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0080, -0.0124, -0.1049, -0.0064,  0.0541,  0.0085,  0.0928, -0.0229,\n",
      "         -0.0246, -0.0421,  0.0960,  0.1239,  0.0411,  0.1166, -0.1277,  0.0453,\n",
      "         -0.0259,  0.0103,  0.1019,  0.1341],\n",
      "        [ 0.0103,  0.0160,  0.1350,  0.0082, -0.0696, -0.0109, -0.1194,  0.0295,\n",
      "          0.0316,  0.0542, -0.1236, -0.1596, -0.0529, -0.1501,  0.1644, -0.0583,\n",
      "          0.0333, -0.0132, -0.1312, -0.1726],\n",
      "        [-0.0017, -0.0027, -0.0230, -0.0014,  0.0118,  0.0019,  0.0203, -0.0050,\n",
      "         -0.0054, -0.0092,  0.0210,  0.0271,  0.0090,  0.0255, -0.0279,  0.0099,\n",
      "         -0.0057,  0.0022,  0.0223,  0.0293],\n",
      "        [ 0.0045,  0.0071,  0.0595,  0.0036, -0.0307, -0.0048, -0.0526,  0.0130,\n",
      "          0.0139,  0.0239, -0.0545, -0.0703, -0.0233, -0.0662,  0.0725, -0.0257,\n",
      "          0.0147, -0.0058, -0.0578, -0.0761],\n",
      "        [-0.0021, -0.0033, -0.0275, -0.0017,  0.0142,  0.0022,  0.0243, -0.0060,\n",
      "         -0.0064, -0.0110,  0.0252,  0.0325,  0.0108,  0.0306, -0.0335,  0.0119,\n",
      "         -0.0068,  0.0027,  0.0267,  0.0351],\n",
      "        [-0.0010, -0.0016, -0.0132, -0.0008,  0.0068,  0.0011,  0.0117, -0.0029,\n",
      "         -0.0031, -0.0053,  0.0121,  0.0156,  0.0052,  0.0147, -0.0160,  0.0057,\n",
      "         -0.0033,  0.0013,  0.0128,  0.0169],\n",
      "        [-0.0075, -0.0116, -0.0978, -0.0059,  0.0504,  0.0079,  0.0864, -0.0213,\n",
      "         -0.0229, -0.0392,  0.0895,  0.1155,  0.0383,  0.1087, -0.1190,  0.0422,\n",
      "         -0.0241,  0.0096,  0.0950,  0.1250],\n",
      "        [ 0.0070,  0.0108,  0.0914,  0.0056, -0.0471, -0.0074, -0.0808,  0.0199,\n",
      "          0.0214,  0.0366, -0.0836, -0.1080, -0.0358, -0.1016,  0.1112, -0.0394,\n",
      "          0.0225, -0.0089, -0.0888, -0.1168],\n",
      "        [-0.0024, -0.0037, -0.0312, -0.0019,  0.0161,  0.0025,  0.0276, -0.0068,\n",
      "         -0.0073, -0.0125,  0.0286,  0.0369,  0.0122,  0.0347, -0.0380,  0.0135,\n",
      "         -0.0077,  0.0031,  0.0303,  0.0399],\n",
      "        [ 0.0050,  0.0078,  0.0657,  0.0040, -0.0339, -0.0053, -0.0581,  0.0143,\n",
      "          0.0154,  0.0264, -0.0601, -0.0776, -0.0257, -0.0730,  0.0800, -0.0283,\n",
      "          0.0162, -0.0064, -0.0638, -0.0840],\n",
      "        [-0.0031, -0.0049, -0.0410, -0.0025,  0.0211,  0.0033,  0.0362, -0.0089,\n",
      "         -0.0096, -0.0164,  0.0375,  0.0484,  0.0161,  0.0456, -0.0499,  0.0177,\n",
      "         -0.0101,  0.0040,  0.0398,  0.0524],\n",
      "        [ 0.0082,  0.0127,  0.1072,  0.0065, -0.0552, -0.0087, -0.0948,  0.0234,\n",
      "          0.0251,  0.0430, -0.0981, -0.1267, -0.0420, -0.1192,  0.1305, -0.0463,\n",
      "          0.0265, -0.0105, -0.1042, -0.1371],\n",
      "        [ 0.0087,  0.0136,  0.1147,  0.0070, -0.0591, -0.0093, -0.1014,  0.0250,\n",
      "          0.0269,  0.0460, -0.1050, -0.1355, -0.0449, -0.1275,  0.1396, -0.0495,\n",
      "          0.0283, -0.0112, -0.1114, -0.1466],\n",
      "        [ 0.0077,  0.0120,  0.1010,  0.0061, -0.0521, -0.0082, -0.0893,  0.0221,\n",
      "          0.0237,  0.0405, -0.0925, -0.1194, -0.0396, -0.1123,  0.1230, -0.0436,\n",
      "          0.0249, -0.0099, -0.0982, -0.1291],\n",
      "        [-0.0022, -0.0035, -0.0293, -0.0018,  0.0151,  0.0024,  0.0259, -0.0064,\n",
      "         -0.0069, -0.0117,  0.0268,  0.0346,  0.0115,  0.0325, -0.0356,  0.0126,\n",
      "         -0.0072,  0.0029,  0.0284,  0.0374],\n",
      "        [ 0.0058,  0.0090,  0.0757,  0.0046, -0.0390, -0.0061, -0.0669,  0.0165,\n",
      "          0.0177,  0.0303, -0.0692, -0.0894, -0.0296, -0.0841,  0.0921, -0.0326,\n",
      "          0.0187, -0.0074, -0.0735, -0.0967],\n",
      "        [-0.0100, -0.0155, -0.1311, -0.0080,  0.0676,  0.0106,  0.1159, -0.0286,\n",
      "         -0.0307, -0.0526,  0.1200,  0.1549,  0.0513,  0.1458, -0.1596,  0.0566,\n",
      "         -0.0324,  0.0128,  0.1274,  0.1676],\n",
      "        [ 0.0041,  0.0064,  0.0536,  0.0033, -0.0276, -0.0043, -0.0474,  0.0117,\n",
      "          0.0126,  0.0215, -0.0491, -0.0633, -0.0210, -0.0596,  0.0653, -0.0231,\n",
      "          0.0132, -0.0052, -0.0521, -0.0685],\n",
      "        [ 0.0009,  0.0015,  0.0124,  0.0008, -0.0064, -0.0010, -0.0110,  0.0027,\n",
      "          0.0029,  0.0050, -0.0114, -0.0147, -0.0049, -0.0138,  0.0151, -0.0054,\n",
      "          0.0031, -0.0012, -0.0121, -0.0159],\n",
      "        [ 0.0009,  0.0014,  0.0118,  0.0007, -0.0061, -0.0010, -0.0105,  0.0026,\n",
      "          0.0028,  0.0048, -0.0108, -0.0140, -0.0046, -0.0132,  0.0144, -0.0051,\n",
      "          0.0029, -0.0012, -0.0115, -0.0151],\n",
      "        [-0.0089, -0.0139, -0.1171, -0.0071,  0.0603,  0.0095,  0.1035, -0.0256,\n",
      "         -0.0274, -0.0470,  0.1071,  0.1383,  0.0458,  0.1301, -0.1425,  0.0505,\n",
      "         -0.0289,  0.0115,  0.1138,  0.1497],\n",
      "        [ 0.0091,  0.0142,  0.1198,  0.0073, -0.0617, -0.0097, -0.1059,  0.0261,\n",
      "          0.0281,  0.0480, -0.1096, -0.1415, -0.0469, -0.1331,  0.1458, -0.0517,\n",
      "          0.0296, -0.0117, -0.1164, -0.1531],\n",
      "        [-0.0008, -0.0012, -0.0099, -0.0006,  0.0051,  0.0008,  0.0088, -0.0022,\n",
      "         -0.0023, -0.0040,  0.0091,  0.0117,  0.0039,  0.0110, -0.0121,  0.0043,\n",
      "         -0.0024,  0.0010,  0.0096,  0.0127],\n",
      "        [ 0.0053,  0.0082,  0.0695,  0.0042, -0.0358, -0.0056, -0.0615,  0.0152,\n",
      "          0.0163,  0.0279, -0.0636, -0.0822, -0.0272, -0.0773,  0.0847, -0.0300,\n",
      "          0.0172, -0.0068, -0.0676, -0.0889],\n",
      "        [ 0.0055,  0.0085,  0.0716,  0.0044, -0.0369, -0.0058, -0.0633,  0.0156,\n",
      "          0.0168,  0.0287, -0.0655, -0.0846, -0.0280, -0.0796,  0.0872, -0.0309,\n",
      "          0.0177, -0.0070, -0.0696, -0.0915],\n",
      "        [-0.0054, -0.0084, -0.0709, -0.0043,  0.0365,  0.0057,  0.0627, -0.0155,\n",
      "         -0.0166, -0.0284,  0.0649,  0.0837,  0.0278,  0.0788, -0.0863,  0.0306,\n",
      "         -0.0175,  0.0069,  0.0689,  0.0906],\n",
      "        [ 0.0022,  0.0034,  0.0289,  0.0018, -0.0149, -0.0023, -0.0256,  0.0063,\n",
      "          0.0068,  0.0116, -0.0265, -0.0342, -0.0113, -0.0322,  0.0352, -0.0125,\n",
      "          0.0071, -0.0028, -0.0281, -0.0370],\n",
      "        [-0.0069, -0.0108, -0.0908, -0.0055,  0.0468,  0.0074,  0.0803, -0.0198,\n",
      "         -0.0213, -0.0364,  0.0831,  0.1073,  0.0356,  0.1010, -0.1106,  0.0392,\n",
      "         -0.0224,  0.0089,  0.0882,  0.1161],\n",
      "        [-0.0046, -0.0071, -0.0598, -0.0036,  0.0308,  0.0048,  0.0529, -0.0131,\n",
      "         -0.0140, -0.0240,  0.0547,  0.0707,  0.0234,  0.0665, -0.0728,  0.0258,\n",
      "         -0.0148,  0.0059,  0.0581,  0.0765],\n",
      "        [ 0.0006,  0.0009,  0.0078,  0.0005, -0.0040, -0.0006, -0.0069,  0.0017,\n",
      "          0.0018,  0.0031, -0.0071, -0.0092, -0.0030, -0.0086,  0.0094, -0.0033,\n",
      "          0.0019, -0.0008, -0.0075, -0.0099]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个三层的MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 30)\n",
    "        self.fc3 = nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型\n",
    "model = MLP()\n",
    "\n",
    "# 冻结第一层和第三层的参数\n",
    "for param in model.fc1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc3.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 定义优化器，仅优化第二层的参数\n",
    "optimizer = torch.optim.SGD(model.fc2.parameters(), lr=0.01)\n",
    "\n",
    "# 模拟一个输入和目标输出\n",
    "input = torch.randn(1, 10)\n",
    "target = torch.randn(1, 1)\n",
    "\n",
    "# 前向传播\n",
    "output = model(input)\n",
    "\n",
    "# 计算loss\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "\n",
    "# 反向传播\n",
    "loss.backward()\n",
    "\n",
    "# 更新权重\n",
    "optimizer.step()\n",
    "\n",
    "# 打印第二层权重的梯度\n",
    "print(model.fc2.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
